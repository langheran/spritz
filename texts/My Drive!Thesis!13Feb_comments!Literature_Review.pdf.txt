Literature Review
Nisim Hurst Wednesday 13 February 2019

Contents

Sub-problem taxonomy definition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parking Block Segmentation from the Camera Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parking Block Segmentation from Aerial Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Vehicle Detection to Segment Parking Blocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Single Parking Spot Detection to Segment Parking Blocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Translation from Aerial Segmentation to Camera Segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A Method for Camera Vision Based Parking Spot Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A Transfer Learning Approach to Parking Lot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Extracting Parking Lot Structures from Aerial Photographs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Extraction of Parking Lot Structure From Aerial Image In Urban Areas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Parking Lot Analysis and Visualization from Aerial Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Parking Spot Detection from Aerial Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Self-Supervised Aerial Image Analysis for Extracting Parking Lot Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 9 9 9 9

Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Unsupervised Recognition of Parking Lot Areas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Vacant On-Street Parking Spot Detection Based on Video Analytics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Integrating Ground and Aerial Views for Urban Site Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Learning to Match Aerial Images with Deep Attentive Architectures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Evidence and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Weaknesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

9 9 9 9 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12

References

12

Sub-problem taxonomy definition
Recall that our problem is to segment parking blocks of arbitrary shapes while providing resiliency to partial occlusions. As far as this study goes, we haven't found any research that could achieve this task. However, a natural breakdown structure of our problem into easier-to-solve subproblems is hereby proposed. Two1 works of Young-Woo Seo relate the parking block segmentation task with the parking block detection task. First, (Seo and Urmson 2009) starts by defining a parking block:
We define a parking block as a row of parking spots all oriented in the same direction. Each parking block is characterized by the distance between neighboring parking spots in the block (i.e., "D1" in figure 1). Parking blocks are related to each other by two distance measures: the distance between conjugate parkingspots (i.e., "D2") and the distance between blocks (i.e., "D3" in the figure 1).
We will use a broader definition that includes also partially occluded parking spots. Also, we include parking blocks of arbitrary shapes onto splines and containing parking spots of different sizes or neighborhood arrangements.
Thus, for parking block detection we will use the same taxonomy proposed by (C. Huang and S. Wang 2010). There, a clear division between parked vehicle detection and free parking spot detection is used to classify the approaches to drive parking block detection. We will further generalize into a higher level generalization by dividing between approaches from the camera perspective and from an aerial perspective. Consequently, we propose the following taxonomy:
1. Parking Block Segmentation from the Camera Perspective. Here, direct approaches to solving the parking block segmentation or parking spot detection problem are described.
1Their second paper from the same year just uses their previous results to construct a road network information between two points and included comparison with a Bayesian learning model. We will talk about this work in due course.

2. Parking Block Segmentation from Aerial Images. Having reviewed the direct approaches, we will look indirect approaches at the aerial domain. We will see how those approaches have lower complexity and higher accuracy bounds. 1. Vehicle Detection to Segment Parking Blocks. Detecting cars is a new possibility ensuing from the change in perspective, nearly inexistent from the camera perspective. Here, we will review works that attempt to use detected cars to parking block detection. 2. Single Parking Spot Detection to Segment Parking Blocks. Most of the methods used in segmenting individual parking blocks on the camera perspective can be used as well on the aerial top-view perspective.
3. Translation from Aerial Segmentation to Camera Segmentation. Finally, we will see the distortions and complexity introduced by translating the solution from one domain to the other.
Parking Block Segmentation from the Camera Perspective
When segmenting the camera perspective image in search of parking block, there are many conditions that can make this task harder. (Weis, May, and Schmidt 2006) classify them in 3 main sources:
1. Typical Attributes. Painted lines, other vehicles, kerbstones, non-plain floor, etc. 2. Road Conditions. Partially damaged parking lines, paving, etc. 3. Surrounding Conditions. Weather, illumination, light source angle, etc.
We didn't found any approach in the literature that detects in the camera view parking blocks from detecting parked vehicles . Conversely, there are many papers that use individual parking spots detection to do so and will be brought into question further on.
The most prominent feature of parking spots viewed from the camera perspective is given by the parking lines. So it is natural that early approaches involve segmenting the parking spots by color areas. Edge detection using a Kirsch filter over color intensities was used in (Weis, May, and Schmidt 2006). There, the authors attempted to detect a parking spot behind a vehicle from its rear camera. As aforementioned, the authors do a great job at characterizing the problem and classify the parking spots into vertical and horizontal.
The results are not conclusive, though. Just four image show the qualitative result by means of overlays, rather than presenting a quantitative complete statistical proof. Also, a range on the size of a parking spot is assumed. Thus, height and width are bounded by the authors common sense and perception. Finally, the proposed method fails to deal with partial occlusions.
One of the most emblematic works in the literature was done in a series of three papers wrote by Huang et al. (C. Huang and S. Wang 2010), (C.-C. Huang et al. 2008) and (Wu et al. 2007). In their work they strive to segment pixels of a static image through a 3-layer hierarchical Bayesian network method that project 3-dimensional cubes over the individual parking spaces per each row. These 3D projections helps the method overcome environmental and car occlusions. Also, they use color to occupancy detection as proposed by (Yamada and Mizuno 2001).
Even though the work of Huang segment areas that belong to parking block, it can not be called dense-prediction. Given that they estimate global parameters and make global assumptions about the canonical parking spot inside the parking lot, they just estimate those parameters without flexibility for the individual cases. Thus, the authors doesn't provide results for the pixel by pixel segmentation, neither the dataset they used to reproduce their results.
Another problem is that the method is dependent on the camera projection parameters. Also a row by row approach is taken to build single-row rectangular parking blocks and parking spots. Also, the authors assumed that occupancy status is independent from one parking spot to the other. This is rarely the case, because normally people park near the building entrance.
There are several observations worth noting. First, none of the approaches were able to overcome occlusions without first making assumptions over the global structure of the parking spots. Second, the methods don't used a direct supervised learning approach to segment the parking spaces.
Now that we have seen how difficult it is for all the previous approaches to overcome occlusions lets see how changing the perspective of the scene change the toolbox to tackle the parking spot detection and parking block segmentation problems.
Parking Block Segmentation from Aerial Images
In contrast to the parking block segmentation from the Camera view domain, from aerial images we found several papers that do approximately the same. We found methods that detect parking blocks of arbitrary proportions though restricted to a rectangular shape. We also found segmentation pixel by pixel of complete parking blocks through fine tuning.
In this section we will briefly review those works in the context of the taxonomy proposed by (C. Huang and S. Wang 2010), i.e. making the distinction between vehicle detection oriented approaches and parking spot detection oriented approaches.
Vehicle Detection to Segment Parking Blocks

Single Parking Spot Detection to Segment Parking Blocks One of the forerunners on this domain was the work of (X. Wang and Hanson 1998). The task performed was detecting parking spots and recovery of the ground texture using completeness and correctness on a single parking spot. Neither learning or training was used. Their method consist of the following. First, an elevation map produced from two images (stereo) is used to first remove vehicles from the ground. Then, a system for automatic surface texture and microstructure extraction (STME) is used to identify individual free parking spots. Also, a oriented region growing algorithm combined with some weight tuning formula is used to extract the parking spots from the previously extracted vehicles. Finally using the combined texture, the method repairs low quality or occluded parking spots. A highly relevant feature of this work is that they transformed their results into a simulation system for the camera view perspective.
Translation from Aerial Segmentation to Camera Segmentation
Translating the results between aerial and ground images is a well studied task. (Lee, S. K. Jung, and Nevatia 2002) showed how to estimate the camera extrinsic and intrinsic parameters and to enrich an aerial image from the ground view. Solving the segmentation and detections problems in a top-view aerial image is simpler than solving it in the camera view. (H. G. Jung et al. 2006) applied an homography to transform the image into an aerial view and then applied the Hough transform to detect parking spot lines. However, usually the image quality is not good after inverse perspective matching. So (Lin and M.-S. Wang 2012) developed a Top-View Transformation Model (TVTM) to generate a better images for parking spot detection. Luckily, nowadays GIS systems provide a second image of the same outdoors scene that obviate that requirement. The work of (Sastre et al. 2007) suggested that a rectification of the camera perspective into an aerial image using an homography can be used for prediction in a supervised task. Under that top-view image, they were able to identify if the parking spot is occupied or not using a SVM over texture feature vectors. Thus, they used a simple symbolic approach based on homomorphisms to solve the linear system of equations given by 4 correspondence points. Those points were given by a human. Nonetheless, (Altwaijry et al. 2016) showed that it is possible to learn these correspondence points using metric learning. Given that the translation from aerial segmentation to camera segmentation.
A Method for Camera Vision Based Parking Spot Detection
The article was written by (Weis, May, and Schmidt 2006). It was was cited 3 times according to Google Scholar. The task performed was detecting parking spot behind a vehicle from its rear camera.
Hypothesis
By using color for edge detection using a Kirsch filter it is possible to detect available parking spots.
Evidence and Results
Four images show parking spot detection. The first shows a parking spot occluded by a car being detected. The second image shows a free parking spot being detected. The third and fourth images show rejections.
Contribution
A first contribution is a thorough problem characterization of detecting a parking spot from a frontal camera. Two different parking spots poses are considered: perpendicular and parallel. The whole method is based in detecting the parking lines and then apply fixed rules to filter them over a semantic analysis. First, the authors pre-process the image to filter out colors and gray levels not belonging to classical parking lines. Then, the authors use a Kirsh filter to vectorize the lines. Finally, semantical filtering is applied.
Weaknesses
No quantitative results are show, just a red overlay over the parking lines and a green frame over the surmised parking spot. A range on the size of a parking spot, i.e. its height and width, is assumed.

Future Work
Apply learning of some kind rather than assume fixed ranges.
A Transfer Learning Approach to Parking Lot
The article was written by (Cisek et al. 2017). It was was cited 0 times according to Google Scholar. The task performed was aerial patch imagery classification using the top 1 error rate and overall accuracy. The main focus of this paper is to compare a CNN with transfer learning based on the AlexNet network and a CNN with weights initialized from scratch.
Hypothesis
Classification accuracy over aerial parking lot patches can be improved by using transfer learning.
Evidence and Results
Dataset The images were obtained from the New York State GIS Clearinghouse. 12,000 image patches of 60x60 pixels with an overlapping of 30 pixels, i.e. there were just 8,000 or less completely different patches to classify. These were used both for training and validation. The target class is either background, parking lot or none.
Evidence The authors tested 2 nets with transfer learning, namely LeNet and AlexNet. The layer architecture was left untouched. Just the learning rate.
Contribution
First, the article provides solid evidence that neural networks can be applied to classify parking lot patches. Second, the article compares performance gains by using transfer learning in two different convolutional network architectures. The dataset used for transfer learning was ILSVRC 2012. A 10.7% overall accuracy improvement was gained by using transfer learning.
Weaknesses
The classification is applied to image patches of arbitrary size, i.e. 60x60 pixels each overlapping by 30 pixels (50%). This patch size limits the features that can be learned in the convolutional layers due to the imposed padding. Also, there is no segmentation, just classification of these image patches of fixed resolution and altitude. Partial occlusions are not considered neither.
Future Work
The authors mention that other CNNs must be tested to establish a more conclusive relation between domain and the usefulness of transfer learning.
Extracting Parking Lot Structures from Aerial Photographs
The article was written by (Cheng et al. 2014). It was was cited 1 times according to Google Scholar. The task performed was individual parking spot detection using correctness and completeness metrics. A second task was determining the parking lot structure in the form of global parameters, i.e. width, length and angle.
Hypothesis
Applying the Hough transform twice after having determined the principle orientations and using this result to estimate global parameters for the size and angle of the parking spots will achieve better than just using the Hough transform.

Evidence and Results
Dataset An aerial image covering 1,500m x 850m with a resolution 5cm per pixel was used. This image includes 3 parking lots with different orientations, occupation density and quality. Parking lot A has 36 parking spots, B 51 spots and C 54; accruing to a total of 141 parking spots.

Results
The results are presented in correctness and completeness. Correctness is the ratio between the correctly extracted parking spaces and the total extracted parking spaces. Completeness is the ratio between correctly extracted parking spaces and the total real parking spaces. A custom individual correctness indicator function that evaluates a set of rules is used, shown in Equation 1.

L1 - L2 < 0.2  L2  W1 - W2 < 0.2  W2
D < (0.2  L2)2 + (0.2  W2)2    < 3

(1)

Error of the global parameters, i.e. length, width and angle is shown as the absolute difference between the real number and the estimated number. Error of the geometrical estimation is calculated by comparing each of the four vectors formed by the four corners of the parking spot to the manually annotated vectors. Mean error, root mean square error and maximum error are used for this comparison.
Contribution
First, the paper provides a method using several optional techniques. Principal orientation calculation is proposed by using Hough transform twice. Also, a self-adaptive growth technique merges the lines. It presents comparative results for this element alone. A second contribution is the resiliency showed over 3 distinct parking lots.
Weaknesses
The metric was defined by the authors without giving any intuition neither on the literature nor stemming from the nature of the problem. Furthermore, the threshold in this metric are assumed and no experimentation was done for calculating it. Also, the canonical width, length and angle are calculated globally on a per-parking basis.
Future Work
The authors propose using the parked vehicles to parking lot extraction. Also, it would be desirable a further algorithm that can detect an accurate parking lot area without human intervention because the method is based on this assumption.
Extraction of Parking Lot Structure From Aerial Image In Urban Areas
The article was written by (Koutaki, Minamoto, and Uchimura 2016). It was was cited 0 times according to Google Scholar. The task performed was detecting rectangular parking lot areas from aerial images. The metric for measuring performance is correctness., i.e. the ratio between the correctly extracted parking lots and the total extracted parking lots. They also use a % of detection metric, equal to the ratio between parking spots correctly extracted and the total real parking spots.
Hypothesis
Combining vehicle detection with parking spot detection will be useful to detect rectangular parking lot structures.

Evidence and Results
Dataset For vehicle detection 2520 positive image patches of 14x32 pixels were used. Likewise, 4800 negative patches were used. For parking space detection a single image patch of 15x28 pixels was used. For parking lot detection, 4 images of 2000x2000 pixels were used. Zoom level is 20cm per pixel. The images were used to train a Haar-like detector in conjunction with an AdaBoost ensemble classifier.
Results The parking lot rows were deduced using hierarchical grouping, starting with those parking spots that their centers are just one width of a parking spot apart. The authors achieved 66.9% completeness detecting vehicles, 30.2% completeness for parking spot detection and correctness of 95% in rectangular parking lot extraction. In the later case, a completeness of 100% is assumed.
Contribution
First, the paper thoroughly defines the geometric structure and appearance model of the parking lot. Second, high resolution elevation data is used to remove buildings. They combined a Digital Elevation Model and a Digital Surface Model with digital interpolation with the 4 urban zone images. Third, a method for extracting those parking lots is proposed. This method is based on extracting both parking spaces and vehicle detection in parallel.
Weaknesses
No comparison with other methods is shown. All the parking lots are assumed to be rectangular. A single angle of 90 degrees between the parking spot and the parking row is assumed.
Future Work
For future work, the authors mention a shadow-resistant vehicle detection and to improve the single parking space extraction. Also, the authors mention that they wish to extend the algorithm to detect parking lots of arbitrary shape.
Parking Lot Analysis and Visualization from Aerial Images
The article was written by (X. Wang and Hanson 1998). It was was cited 35 times according to Google Scholar. The task performed was detecting parking spots and recovery of the ground texture using completeness and correctness on a single parking spot. Neither learning or training was used.
Hypothesis
3D vehicle elevation data can be combined with a texture recognition system to generate a clean parking lot surface. This surface can then be used to simulate parking lot activities.
Evidence and Results
Dataset There is just a pair of high resolution images from the Lockheed/Martin military complex. These images have a total of 77 parking spots lines.
Results Parking spot marker detection confusion matrix intermediate results is presented. From the 77 actual markers just 59 were correctly extracted, a completeness of 76%. Clustering is applied to parking spot widths hypothesis. The global average width is calculated and these results are also presented. Finally, the final result is a full 3D reconstruction of the parking lot areas (without any further metric for measuring accuracy).

Contribution
First, an elevation map produced from two images (stereo) is used to first distinguish vehicles from the ground. A system for automatic surface texture and microstructure extraction (STME) is used to identify individual free parking spots. Also, a oriented region growing algorithm combined with some weight tuning formula is used to extract the parking spots from the previously extracted vehicles. Finally using the combined texture, the method repairs low quality or occluded parking spots.
Weaknesses
The method treats each parking spot as part of a texture and assume this texture is constant through the parking lot image. Thus, it seeks to calculate the dimension parameters globally. This means that if we had parking spots of arbitrary distinct sizes the method would fail. Also, if the parking lot is full, the texture detection phase becomes unreliable because there a not much visible parking spot markers.
Future Work
Shadows can be used as a cue to separate individual parking spots, as proposed by Chellappa.
Parking Spot Detection from Aerial Images
The article was written by (Kabak and Turgut 2010). It was was cited 3 times according to Google Scholar. The task performed was predicting occupancy using image segmentation to extract features. They used overall accuracy, recall, precision and specificiy to over the labeled parking spots.
Hypothesis
Image segmentation provides the necessary means to extract features and apply a machine learning algorithm for binary classification, namely a support vector machine, and achieve good results in occupancy detection.
Evidence and Results
Dataset Seven images were extracted at 133 feets and 1661x1091 resolution. The authors used Google Earth over Cambridge, UK. From these 7 images parking spots were marked individually, differentiating between 135 available and 215 occupied parking spots for training. For testing, 34 available and 54 occupied images were used.
Results Given that the data is fairly balanced, occupancy detection is measured through overall accuracy, recall precision and specificity. Confusion matrices for the training and testing sets are also shown. A second chart shows how accuracy is affected by increasing the minimum segmentation area for the mean shift function. This parameter is the only one that need to be manually tuned. A 200-pixels segmented area was found to be optimal.
Contribution
First, the authors present a list of intuitive eight features to classify the occupancy for each parking spot. Hold-out cross validation was used to filter out 20% of the less useful features. A second contribution is a method for determining the best features extracted in part with the help of mean shift segmentation. Finally, an SVM (LIBLINEAR solver) is used with unsurprising good results.

Weaknesses
First, the authors don't provide the full list of features before pruning. They just provide 8 of the 40 supposedly intuitive features. These results are crucial for extending the feature list and reproducing the papers results. Nonetheless, the method is susceptible to the minimal segmentation area that has to be set by a human. Upper and lower bounds for calculating the optimal one are not clear from context. An explicit relation between the image meters per pixel resolution would be desirable. Also, there exist visible correlation between the features, e.g. Luv color is used in three distinct features. Unlike ANNs, SVMs are vulnerable to this kind of correlations. Given that we have more than 3 features using the same latent variable for calculating the separation hyperplane, it won't be useful to normalize.
Future Work
The authors doesn't explicitly provide future work hints. However, other type of image preprocessing algorithms based on edge detection could be applied. Also, future work could include to test other machine learning algorithms, e.g. an ensemble of shallow decision stumps using all the features. This strategy could take care of pruning the most important features without having to explicitly delete them. Finally, given that the only tested kernel in the SVM was the linear one, future work could include testing other kernels, i.e. the radial basis function kernel. For the distance metric, Mahalanobis could prove useful to take into account correlations.
Self-Supervised Aerial Image Analysis for Extracting Parking Lot Structure
The article was written by (Seo, Ratliff, and Urmson 2009). It was was cited 19 times according to Google Scholar. The task performed was estimating the parking lot structure from single parking spot detection using overall accuracy metric. The structure in this case is given by the global height, width, orientation and centroid location alignment.
Hypothesis
A method that takes advantage of self-supervised low level (parking spot level) training will minimize human intervention while accurately estimate the parking lot structure.
Evidence and Results
Dataset Thirteen aerial images were collected from Google maps service. Those images have about 147 visible parking spots on average, adding up to 1912 parking spots in total.
Results Evidence is presented in two parts. First, the overall accuracy of the initial estimates of the low-level line clustering and parking blocks method with their correspondence false positive and false negative rates. A false positive is considered more problematic because it would guide an autonomous robot to drive in unsafe places. Then, three self-supervised classifiers are evaluated, namely: 1. Support Vector Machines, 2. Eigenspots and 3. Pairwise Markov Random Fields (with GMM). A fourth model combining Eigenspots and SVMs is also included in the test battery. Their results are presented contrasting the results obtained by training using the canonical parking spots alone and training by first enriching the dataset with self-supervised sample generation.
Contribution
The main contribution of the paper is the comparison of the self-supervised approach vs the supervised approach through several machine learning models. A second contribution is a serial method that consist of the following high level steps:
1. Generate the parking spot global size parameters. 2. Generate canonical parking spots templates. 3. Generate initial parking spot estimates. 4. Calculate global distances between the parking spots. 5. Interpolate and extrapolate parking spot centroids in a single row.

6. Filter the hypothesis using the templates for self-supervised classifiers.
Weaknesses
The angle between the parking spots and the parking block is assumed fixed to 90 degrees. Also, distances that define the parking row structure and individual parking spot parameters are calculated globally.
Future Work
The authors propose using more machine learning trainable models that incorporate prior information to get a conclusive idea of the accuracy gain by using the self-supervised approach for this task. Histogram of Oriented Gradients is also proposed to extract more sophisticated feature representations.
Unsupervised Recognition of Parking Lot Areas
The article was written by (Mexas and Marengoni n.d.). It was was cited 0 times according to Google Scholar. The task performed was pixel segmentation using merging of parking spots and parked vehicles. The used metric was true positive rate (hit rate) over a single parking lot.
Hypothesis
Combining parked vehicle and free parking spots detection over high resolution images using morphological operations is enough to recognize parking lot areas without depending on any training method.
Evidence and Results
Dataset A single Brazilian parking lot image was used. It has a resolution of 15 cm per pixel and size of 1000 x 1000 pixels.
Results The results are presented in a single table with hit rate, false negative rate and false positive rate for a single image.
Contribution
The most important contribution is the enumeration of tunable parameters that can be used to identify parking lot areas without any training. A corollary contribution is the proof that a single image alone (and purportedly simple human tuning) is sufficient to recognize parking lots. The method is based in the following steps:
1. Identification of parked vehicles. 1. Apply morphological operations 2. Search using man-made rules
2. Identification of free parking spots. 1. Apply morphological operations 2. Search using man-made rules
3. Hierarchical merging of segmented areas below a pixel Euclidean distance threshold. All the previous steeps are parametrizable.
Weaknesses
The paper obviate comparison by variating the parameter values. Thus, we can assure without loss of precision, that they used human intuition alone. Therefore, the results are not statistically guarantied to be optimal. However, it constitutes a proof of concept that identifies a properly included set of parameters that can be optimized by an unattended algorithm.

Future Work The title of this work is misleading. Clearly, this work relies heavily on human input for supervising the tuning of all parameters. Any improvement to reduce the number of parameters to be estimated by a human would be highly beneficial. Also, the authors mention that the system is vulnerable to roof with repetitive patterns, shadows and not parked vehicles. Thus, a probabilistic approach to filter out those cases considering global features of the parking spots could also be developed.
Vacant On-Street Parking Spot Detection Based on Video Analytics
The article was written by (Sevillano, Màrmol, and Fernandez-Arguedas 2014). It was was cited 15 times according to Google Scholar. The task performed was x using y metric over z.
Hypothesis Evidence and Results Dataset
Results
Contribution Huang and Wang proposed a categorization of the existing methods into car-driven and space-driven.
Weaknesses Future Work
Integrating Ground and Aerial Views for Urban Site Modeling
The article was written by (1047411). It was was cited 25 times according to Google Scholar. The task performed was x using y metric over z.
Hypothesis Evidence and Results Dataset
Results
Contribution Weaknesses Future Work
Learning to Match Aerial Images with Deep Attentive Architectures
The article was written by (Altwaijry et al. 2016). It was was cited 40 times according to Google Scholar. The task performed was x using y metric over z.

Hypothesis
Evidence and Results
Dataset
Results
Contribution
Weaknesses
Future Work
References
Altwaijry, Hani et al. (June 2016). "Learning to Match Aerial Images With Deep Attentive Architectures". In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
Cheng, Liang et al. (Feb. 2014). "Extracting Parking Lot Structures from Aerial Photographs". In: Photogrammetric Engineering & Remote Sensing 80.2, pp. 151­160. doi: 10.14358/pers.80.2.151-160. url: https://doi.org/10.14358%2Fpers.80.2.151-160.
Cisek, D. et al. (Aug. 2017). "A transfer learning approach to parking lot classification in aerial imagery". In: 2017 New York Scientific Data Summit (NYSDS), pp. 1­5. doi: 10.1109/NYSDS.2017.8085049.
Huang, C. and S. Wang (Dec. 2010). "A Hierarchical Bayesian Generation Framework for Vacant Parking Space Detection". In: IEEE Transactions on Circuits and Systems for Video Technology 20.12, pp. 1770­1785. issn: 1051-8215. doi: 10.1109/TCSVT.2010.2087510.
Huang, Ching-Chun et al. (Mar. 2008). "A Bayesian hierarchical detection framework for parking space detection". In: 2008 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE. doi: 10.1109/icassp.2008.4518055. url: https://doi.org/10.1109%2Ficassp. 2008.4518055.
Jung, Ho Gi et al. (June 2006). "Parking Slot Markings Recognition for Automatic Parking Assist System". In: 2006 IEEE Intelligent Vehicles Symposium, pp. 106­113. doi: 10.1109/IVS.2006.1689613.
Kabak, Mehmet Ozan and Ozhan Turgut (2010). "Parking spot detection from aerial images". In: Stanford University, Final Project Autumn 2010, Machine Learning class.
Koutaki, Gou, Takamochi Minamoto, and Keiichi Uchimura (2016). "EXTRACTION OF PARKING LOT STRUCTURE FROM AERIAL IMAGE IN URBAN AREAS". In: INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL 12.2, pp. 371­383.
Lee, Sung Chun, Soon Ki Jung, and Ramakant Nevatia (Aug. 2002). "Integrating ground and aerial views for urban site modeling". In: Object recognition supported by user interaction for service robots. Vol. 4, 107­112 vol.4. doi: 10.1109/ICPR.2002.1047411.
Lin, Chien-Chuan and Ming-Shi Wang (2012). "A Vision Based Top-View Transformation Model for a Vehicle Parking Assistant". In: Sensors 12.4, pp. 4431­4446. issn: 1424-8220. doi: 10.3390/s120404431. url: http://www.mdpi.com/1424-8220/12/4/4431.
Mexas, Antonio H and Mauricio Marengoni (n.d.). "Unsupervised Recognition of Parking Lot Areas". In: (). Sastre, R. J. L. et al. (June 2007). "Computer Algebra Algorithms Applied to Computer Vision in a Parking Management System". In: 2007
IEEE International Symposium on Industrial Electronics, pp. 1675­1680. doi: 10.1109/ISIE.2007.4374856. Seo, Young-Woo, Nathan D Ratliff, and Chris Urmson (2009). "Self-Supervised Aerial Image Analysis for Extracting Parking Lot Structure."
In: International Joint Conferences on Artificial Intelligence, pp. 1837­1842. Seo, Young-Woo and Chris Urmson (Oct. 2009). "Utilizing prior information to enhance self-supervised aerial image analysis for extracting
parking lot structures". In: 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE. doi: 10.1109/iros.2009. 5354405. url: https://doi.org/10.1109%2Firos.2009.5354405. Sevillano, Xavier, Elena Màrmol, and Virginia Fernandez-Arguedas (2014). "Towards smart traffic management systems: Vacant on-street parking spot detection based on video analytics". In: Information Fusion (FUSION), 2014 17th International Conference on. IEEE, pp. 1­8. Wang, Xiaoguang and Allen R Hanson (1998). "Parking lot analysis and visualization from aerial images". In: Proceedings Fourth IEEE Workshop on Applications of Computer Vision. WACV'98 (Cat. No.98EX201), pp. 36­41. doi: 10 . 1109 / acv . 1998 . 732855. url: https://doi.org/10.1109%2Facv.1998.732855. Weis, Tim, Benjamin May, and Christian Schmidt (Apr. 2006). "A Method for Camera Vision Based Parking Spot Detection". In: SAE Technical Paper Series. SAE International. doi: 10.4271/2006-01-1290. url: https://doi.org/10.4271%2F2006-01-1290. Wu, Q. et al. (July 2007). "Robust Parking Space Detection Considering Inter-Space Correlation". In: 2007 IEEE International Conference on Multimedia and Expo, pp. 659­662. doi: 10.1109/ICME.2007.4284736. Yamada, Keiichi and Morimichi Mizuno (2001). "A vehicle parking detection method using image segmentation". In: Electronics and Communications in Japan (Part III: Fundamental Electronic Science) 84.10, pp. 25­34. doi: 10.1002/ecjc.1039. url: https://doi.org/10. 1002%2Fecjc.1039.

