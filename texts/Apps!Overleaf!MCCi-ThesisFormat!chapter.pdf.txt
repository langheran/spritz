Chapter 1
Introduction
Convolutional Neural Networks
Convolutional Neural Networks are by far the most popular neural network applied to computer vision. They are specially useful when dealing with static images of variable size. In contrast with traditional fully connected neural networks in which there is exactly one weight to be used once per input, it uses a small kernel aimed at detecting edges. The motivation of this kind of network is to learn a shared set of parameters.
1. Sparse interactions. Makes the kernel smaller than the input. 2. Parameter sharing. 3. Equivalent representation. However, convolutional layers are sensitive to rotation and scaling. By using small pooling filters texture detection is made invariant for regions covered by the filter. The most common pooling layer is max-pooling.
Affine Normalization
Affine normalization is a function between affine spaces that preserves points, straight lines and planes. In a neural network we use it to restore the representational power with two vectors of trainable parameters, one that is a coefficient of the input vector and one independent for a bias.
Residual Neural Units
When the computational graphs becomes extremely deep, the application of the same weight parameters is equivalent to multiplying the matrix to the power of t . By eigendecomposition, if the matrix is square, diagonalizable and normal then the matrix function becomes:
W t = (V diag()V -1)t = V diag()tV -1 For small eigenvalues the matrix becomes nilpotent, for large eigenvalues it explodes. This problem is called the vanishing and exploding gradients. Vanishing gradients makes impossible to tell were the weights should be heading to improve the cost function. Exploding gradients makes learning unstable.
1

Residual blocks were presented on [?] to circumvent these problems. Residual neural networks seek to reformulate the layers with a reference to the layers input. That makes the identity function easier to learn equally well through out all the layers. So,the weights can easily become zero and allow the identity function to be passed to the next layer as needed:
a[l+2] = g(z[l+1] + a[l]) = g(w[l+1] + b[l+1] + a[l]) = g(0 + 0 + a[l]) = a[l]
Problem characterization
In this section we first characterize the satellite image segmentation:  Parking lots viewed from the space  Texture appearance prevails over other features  The view is orthogonal  Each image is the same scale  Instances can be rotated and form a manifold with the sole condition they do not overlap  Variable angle relative to the road, no more than 180 degrees
2

