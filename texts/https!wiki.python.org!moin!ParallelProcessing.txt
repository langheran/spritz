batchlib - a distributed computation system with automatic selection of processing services (no longer developed)

Celery - a distributed task queue based on distributed message passing

Deap is a evolutionary algorithm library, which contains a parallelization module named DTM, standing for Distributed Task Manager, which allows an easy parallelization over a cluster of computers. This module can be used separately -- e.g. to compute something else than evolutionary algorithms -- and offers an interface similar to the multiprocessing.Pool module (map, apply, synchronous or asynchronous spawns, etc.), providing a complete abstraction of the startup process and the communication and load balancing layers. It currently works over MPI, with mpi4py or PyMPI, or directly over TCP. Its unique structure allows some interesting features, like nested parallel map (a parallel map calling another distributed operation, and so on).

disco - an implementation of map-reduce. Developed by Nokia. Core written in Erlang, jobs in Python. Inspired by Google's mapreduce and Apache hadoop.

dispy - Python module for distributing computations (functions or programs) along with any dependencies (files, other Python functions, classes, modules) to nodes connected via network. The computations can be scheduled by supplying arguments in SIMD style of parallel processing. The nodes can be shared by multiple processes/users simultaneously if desired. dispy is implemented with asynchronous sockets, coroutines and efficient polling mechanisms for high performance and scalability.

DistributedPython - Very simple Python distributed computing framework, using ssh and the multiprocessing and subprocess modules. At the top level, you generate a list of command lines and simply request they be executed in parallel. Works in Python 2.6 and 3.

exec_proxy - a system for executing arbitrary programs and transferring files (no longer developed)

execnet - asynchronous execution of client-provided code fragments (formerly py.execnet)

IPython - the IPython shell supports interactive parallel computing across multiple IPython instances

job_stream - An MPI/multiprocessing-based library for easy, distributed pipeline processing, with an emphasis on running scientific simulations. Uses decorators in a way that allows users to organize their code similarly to a traditional, non-distributed application. Can be used to realize map/reduce or more complicated distributed frameworks. Python 3 and 2.7+ compatible.

jug - A task based parallel framework

mpi4py - MPI-based solution

NetWorkSpaces appears to be a rebranding and rebinding of Lindaspaces for Python

PaPy - Parallel(uses multiprocessing) and distributed(uses RPyC) work-flow engine, with a distributed imap implementation.

papyros - lightweight master-slave based parallel processing. Clients submit jobs to a master object which is monitored by one or more slave objects that do the real work. Two main implementations are currently provided, one using multiple threads and one multiple processes in one or more hosts through Pyro.

pp (Parallel Python) - "is a python module which provides mechanism for parallel execution of python code on SMP (systems with multiple processors or cores) and clusters (computers connected via network)."

PyCOMPSs - A task based a programming model which aims to ease the development of parallel applications for distributed infrastructures, such as Clusters and Clouds. Offers a sequential interface, but at execution time the runtime system is able to exploit the inherent parallelism of applications at task level.

PyLinda - distributed computing using tuple spaces

pyMPI - MPI-based solution

pypar - Numeric Python and MPI-based solution

pyPastSet - tuple-based structured distributed shared memory system in Python using the powerful Pyro distributed object framework for the core communication.

pypvm - PVM-based solution

pynpvm - PVM-based solution for NumPy

Pyro PYthon Remote Objects, distributed object system, takes care of network communication between your objects once you split them over different machines on the network

Ray - Parallel and distributed process-based execution framework which uses a lightweight API based on dynamic task graphs and actors to flexibly express a wide range of applications. Uses shared-memory and zero-copy serialization for efficient data handling within a single machine. Provides recovery from process and machine failures. Uses a bottom-up hierarchical scheduling scheme to support low-latency and high-throughput task scheduling. Includes higher-level libraries for machine learning and AI applications. Supports Python 2 and 3. (Linux, Mac)

rthread - distributed execution of functions via SSH

ScientificPython contains three subpackages for parallel computing:

Scientific.DistributedComputing.MasterSlave implements a master-slave model in which a master process requests computational tasks that are executed by an arbitrary number of slave processes. The strong points are ease of use and the possibility to work with a varying number of slave process. It is less suited for the construction of large, modular parallel applications. Ideal for parallel scripting. Uses "Pyro". (works wherever Pyro works)

Scientific.BSP is an object-oriented implementation of the "Bulk Synchronous Parallel (BSP)" model for parallel computing, whose main advantages over message passing are the impossibility of deadlocks and the possibility to evaluate the computational cost of an algorithm as a function of machine parameters. The Python implementation of BSP features parallel data objects, communication of arbitrary Python objects, and a framework for defining distributed data objects implementing parallelized methods. (works on all platforms that have an MPI library or an implementation of BSPlib)

Scientific.MPI is an interface to MPI that emphasizes the possibility to combine Python and C code, both using MPI. Contrary to pypar and pyMPI, it does not support the communication of arbitrary Python objects, being instead optimized for Numeric/NumPy arrays. (works on all platforms that have an MPI library)

SCOOP (Scalable COncurrent Operations in Python) is a distributed task module allowing concurrent parallel programming on various environments, from heterogeneous grids to supercomputers. It provides a parallel map function, among others.

seppo - based on Pyro mobile code, providing a parallel map function which evaluates each iteration "in a different process, possibly in a different computer".

"Star-P for Python is an interactive parallel computing platform ..."

superpy distributes python programs across a cluster of machines or across multiple processors on a single machine. Key features include:

Send tasks to remote servers or to same machine via XML RPC call
GUI to launch, monitor, and kill remote tasks
GUI can automatically launch tasks every day, hour, etc.
Works on the Microsoft Windows operating system
Can run as a windows service
Jobs submitted to windows can run as submitting user or as service user
Inputs/outputs are python objects via python pickle
Pure python implementation
Supports simple load-balancing to send tasks to best servers