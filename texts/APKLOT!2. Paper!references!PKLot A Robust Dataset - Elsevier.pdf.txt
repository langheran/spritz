Expert Systems with Applications 42 (2015) 4937­4949
Contents lists available at ScienceDirect
Expert Systems with Applications
journal homepage: www.elsevier.com/locate/eswa

PKLot ­ A robust dataset for parking lot classification
Paulo R.L. de Almeida a, Luiz S. Oliveira a, Alceu S. Britto Jr. b,, Eunelson J. Silva Jr. b Alessandro L. Koerich b,c
a Federal University of Parana, Department of Informatics, R. Cel. Francisco H. dos Santos, 100, Curitiba, PR 81531-990, Brazil b Pontifical Catholic University of Parana, Graduate Program in Informatics (PPGIa), R. Imaculada Conceicao, 1155, Curitiba, PR 80215-901, Brazil c École de Technologie Supérieure, Département de génie logiciel et des TI, 1100 rue Notre-Dame Ouest, Montréal, QC H3C 1K3, Canada

article info
Article history: Available online 19 February 2015
Keywords: Parking space detection Textural-based descriptors Parking space classification Parking space dataset

abstract
Outdoor parking lot vacancy detection systems have attracted a great deal of attention in the last decade due the large number of practical applications. However, a common problem that researchers in this field very often face is the lack of a representative dataset to perform their experiments. To mitigate this difficulty, in this paper we introduce a new parking lot dataset composed of 695,899 images captured from two parking lots with three different camera views. The acquisition protocol allows obtaining static images showing illumination variance related to sunny, overcast and rainy days. We believe that researchers will find this dataset a very useful tool since it allows future benchmarking and evaluation. The dataset is currently available for research purposes upon request. To gain a better insight into this dataset we have evaluated two textural descriptors, Local Binary Patterns and Local Phase Quantization, with a Support Vector Machine classifier to detect parking lot vacancy. In the experiments where the same view was used for both training and testing, we have reached outstanding recognition rates, greater than 99%. The main challenge, though, lies in building a general classifier that is able to detect parking spaces from the parking lots that were not used for training. In this sense, the best result achieved by the texture-based classifier was about 89%. The observed drop in terms of performance shows that additional investigation is necessary to create classification schemes less dependent on the training set. Other researchers can use these results as a baseline performance when testing their own algorithms on this dataset.
Ó 2015 Elsevier Ltd. All rights reserved.

1. Introduction
Finding a vacant space in parking lots of large metropolitan areas may frequently becomes exhausting. Apart from stressful, this challenging task usually consumes considerable time and money. In addition, it contributes to pollute the environment with CO2 emissions. Trying to solve this problem, the industry offers solutions based on different technologies that can be categorized into counter-based, sensor-based, and image-based.
Counter-based systems count the number of vehicles entering and exiting the parking area. To this end, it uses gate-arm counters and inductive loop detectors located at the entrances and exits. This kind of system can inform the total number of vacant lots in a closed car park area, but does not help much in guiding the driver to the exact location of the vacant lots. It is commonly employed in great outdoor parking lots due to its relatively low cost. Sensor-
 Corresponding author.
E-mail addresses: prlalmeida@inf.ufpr.br (P.R.L. de Almeida), lesoliveira@inf. ufpr.br (L.S. Oliveira), alceu@ppgia.pucpr.br (A.S. Britto Jr.), eunelson@ppgia.pucpr. br (E.J. Silva Jr.), alessandro.koerich@etsmtl.ca (A.L. Koerich).
http://dx.doi.org/10.1016/j.eswa.2015.02.009 0957-4174/Ó 2015 Elsevier Ltd. All rights reserved.

based systems (Chunhe & Jilin, 2004; Wolff et al., 2006), take into account detection sensors such as ultrasonic sensors which are installed at each parking space. This information is then relayed to display panels at strategic locations in the parking lot. The display panels provide information, direction and guide the drivers to vacant parking spaces. The main drawback of the sensor-based approach is the cost for developing the system because the large amount of sensors units required to cover the entire parking lot.
The third category is based on image or video processing. Those who advocate against the use of image-based techniques say that video cameras are remarkable expensive sensors which generate large amount of data that may be difficult to transmit over a wireless network (Tang, Zheng, & Cao, 2006). On the other hand, the literature shows that image-based parking space detection systems can be deployed using existing surveillance cameras that are already connected to a central monitoring system (Ichihashi, Notsu, Honda, Katada, & Fujiyoshi, 2009). It turns out that imagebased systems are a good alternative for large and outdoor parking lots where the installation of hundreds or even thousands of sensors are unfeasible.

4938

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

Fig. 1. Example of a parking lot.

Huang and Wang (2010) show that image-based systems can be classified into two categories: car-driven and space-driven. In the former, algorithms are developed to detect cars, which are the objects of interest. In this vein, there are several object detection algorithms that can be used (Schneiderman & Kanade, 2004; Viola & Jones, 2004). Because of the perspective distortion, observed in most images of parking lots (e.g. Fig. 1) a car far away occupies a small area, hence, features few details which degrades considerably the performance of the object detection algorithms. In fact, it depends on the position of the camera. Therefore objects far away from the camera are represented by less pixels than objects that are close.
For the space-driven, the focus lies on detecting empty spaces rather than vehicles (Funck, Mohler, & Oertel, 2004; Lee, Wen, Han, & Kou, 2005). For static cameras, such as the surveillance cameras, the most used strategy is the background subtraction (Horprasert, Harwood, & Davis, 1999), which assumes that the variation of the background is statistically stationary within a short period. Since this hypothesis does not hold for outdoor scenes, this strategy shows rapidly its limits. A more robust approach was proposed by Sastre, Gil Jimenez, Acevedo, and Maldonado Bascon (2007) where they used Gabor filters as feature extractor to train a classifier with empty spaces under different light conditions.
A mix of both car- and space-driven approach has been proposed by several authors by modeling both vehicles and empty spaces using different sorts of features and classification algorithms. Support Vector Machine (SVM) is certainly the most used machine learning algorithm, while color is the most employed descriptor (Bong, Ting, & Lai, 2008; Huang & Wang, 2010; Lin, Chen, & Liu, 2006; Wu, Huang, yu Wang, Chiu, & Chen, 2007). The performance of color-based systems, however, may be considerably affected by changes of lighting conditions. With this in mind, other families of features have been investigated, such as Edges (Bin, Dalin, Fang, & Tingting, 2009), Principal Component Analysis (PCA) (Ichihashi et al., 2009), and Optical Flow (Yu & Chen, 2009).
Recently, Huang, Tai, and Wang (2013) presented an extended version of their work presented in Huang and Wang (2010). The main novelty is the processing of nighttime images by considering a preprocessing to enhance the image quality. To this end, the authors combine multiple images captured with different exposure settings. The resulting preprocessed images are very similar to those taken on the evening. They reported interesting results on their own dataset. Similarly, in Jermsak, Umair, Abdulhamid, Haiwei, and Nikolaos (2014), the authors trained two classifiers

one for daytime and other for nighttime images, both trained on pixel based features related to light, color, edge and time (difference between adjacent frames). They reported robust results for both classifiers in a one-day long evaluation based on 126 parking spots.
Despite the importance of the aforementioned contributions, the parking space classification is still an open problem. A major challenge to pursuing research involving parking space classification is the lack of a consistent and reliable dataset. To the best of our knowledge, the datasets reported in the literature usually suffer from at least one of the following constraints: (a) it contains few samples; (b) all image samples are related to the same parking lot; (c) the image samples do not adequately cover the significant changes of lighting conditions caused by sunny, overcast and rainy days.
To overcome this problem, the main contribution of this work is to present the PKLot, a robust image dataset of parking lots which is an extended version of the one introduced in Almeida, Oliveira, Silva, Britto Jr, and Koerich (2013). It was extended from 105,837 to 695,899 images. In this new version, the parking spaces were captured from different parking lots under varied weather conditions. Each parking space image was manually checked and classified according to its situation (vacant or occupied) and to the weather condition observed during the image acquisition (sunny, overcast or rainy). The PKLot is available for research purposes under request.1 In addition, through a set of comprehensive experiments, we demonstrate that texture descriptors are a good alternative for the detection of empty or occupied parking spaces. The experimental protocol created on the basis of the PKLot dataset, allow us to assess the developed textural-based classifiers on images captured from different parking lots and under significant changes in lightning conditions.
The core of the proposed method is formed by two textural descriptors, Local Binary Patterns (LBP) and Local Phase Quantization (LPQ). These two descriptors have attracted a great deal of attention in the last years because of their performance in a number of applications (Costa, Oliveira, Koerich, Gouyon, & Martins, 2012; Filho, Oliveira, Nisgoski, & Britto, 2014; Mansano, Pavesi, Oliveira, Britto Jr, & Koerich, 2011; Rahtu, Heikkilä, Ojansivu, & Ahonen, 2012; Zavaschi, Britto, Oliveira, & Koerich, 2013). The concept of the LBP was first proposed in Ojala, Pietikäinen, and Harwood (1996) as a simple approach, robust in terms of grayscale variations, which proved its ability to efficiently
1 http://web.inf.ufpr.br/vri/parking-lot-database.

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

4939

discriminate among a wide range of rotated textures. Later, they extended their work (Ojala, Pietikainen, & Maenpaa, 2002) to produce a grayscale and rotation invariant texture operator. The concept of LPQ was originally proposed by Ojansivu and Heikkilä (2008), and has been shown to be robust in terms of blur, and to outperform LBP in texture classification (Ojansivu, Rahtu, & Heikkila, 2008).
Besides the standard versions of the LBP and LPQ, we also have evaluated some variations such as the LBP Rotation Invariant, LPQ with Gaussian window and LPQ Gaussian derivative quadrature filter pair. The results reported in this study show that the Support Vector Machine (SVM) classifiers trained with these textural-base descriptors are able to achieve, when combined, a correct classification rate of 99:64%. In addition, experiments on parking lots that have not contributed with images for training the classifiers allow us to show some loss in terms of accuracy (11:9 percentage points in average). These experiments are used to introduce the PKLot dataset, while the obtained results can be considered as a baseline performance for further researches.
This paper is organized as follows. Section 2 introduces the PKLot dataset presenting its main characteristics. Section 3 describes an evaluation protocol based on the PKLot dataset. Section 4 describes the textural features used in the experiments undertaken to construct and assess the proposed parking lot detection method. The experiments and corresponding results are shown in Section 5. Finally, Section 6 presents our conclusions and insights for future work.
2. The PKLot dataset
The PKLot dataset contains 12,417 images of parking lots and 695,899 images of parking spaces segmented from them, which were manually checked and labeled. All images were acquired at the parking lots of the Federal University of Parana (UFPR) and the Pontifical Catholic University of Parana (PUCPR), both located in Curitiba, Brazil. The protocol used to construct the PKLot dataset is composed of three steps, as follows:

 Image acquisition: this process was defined to be executed with a 5-min time-lapse interval for a period of more than 30 days by means of a low cost full high definition camera (Microsoft LifeCam, HD-5000) positioned at the top of a building to minimize the possible occlusion between adjacent vehicles. The main goal was to obtain images under different weather conditions (overcast, sunny, and rainy periods) by registering at each 5 min the environment changes. Such a setup, allows to capture sequences of images showing high variability in terms of illumination occasioned by weather changes. For instance, in a short period it is possible to observe light rain, heavy rain, and after rain conditions. Unfortunately, we do not have night shots since the illumination available in the parking lots was not sufficient to acquire good quality images. The resulting images were stored in JPEG color format with lossless compression (quality 100%) in a resolution of 1280 Â 720 pixels. They were organized into three subsets named UFPR04, UFPR05 and PUCPR. The first two contain images of different views of the same parking lot captured from the 4th and 5th floors of the UFPR building. The last dataset contains images captured from the 10th floor of the administration building of the PUCPR. Fig. 2 shows some image samples of the three parking lots captured under the aforementioned weather conditions. It is possible to observe some challenges posed by this dataset, such as: sunny images (Fig. 2(a)) presenting overexposed cars and shadows caused by the trees; or images acquired under heavy rain (Fig. 2(c)) that look like night images due the lack of natural light.
 Labeling: for each parking lot image was created an Extensible Markup Language (XML) file containing the position and situation (vacant or occupied) of each parking space. An interactive tool was developed to label the images. Such a tool allows the visualization of each image and the definition of the limits of each parking space (represented by points of a polygon), as well as the situation (vacant or occupied). Different subfolders were used to manually categorize the images according to the observed weather condition (overcast, sunny, or rainy period).

Fig. 2. Images captured under different weather conditions: (a) sunny (b) overcast, and (c) rainy from UFPR04; (d) sunny (e) overcast, and (f) rainy from UFPR05; and (g) sunny (h) overcast, and (i) rainy from PUCPR.

4940

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

 Segmentation: the individual parking spaces were extracted from each parking lot image using the information available in the corresponding XML file. In addition, the slope of the rectangle containing the parking space image was modified according to the scheme presented in Fig. 3. Those with less than 45 were rotated to 0, while those with more than 45 were rotated to 90. Fig. 4(a) shows an image where the 28 available spaces are marked in green. It is important to mention that only valid parking spaces were labeled and segmented. Valid parking spaces are those signed (delimited) with parallel yellow or white lines on the floor. As one can notice, there are some cars parked in an unauthorized manner, i.e., in the middle of the street. Two samples of the segmented parking spaces are depicted in Fig. 4(b) (occupied) and (c) (empty).
Table 1 summarizes the general characteristics of each subset. As one may see, for instance, the images captured from the subset UFPR04 allow us to monitor 28 individual spaces. This subset contains 3791 images captured under different weather conditions. After a semi-automatic segmentation process and a manual checking and labeling, it sums up 105,845 images of individual lots, 43.48% occupied and 56.42% empty. Similar information is provided for the UFPR05 and PUCPR subsets.
Here is a short summary of what makes this dataset interesting to computer vision research community:
(i) Images covering different climatic conditions (sunny, rainy and overcast periods) were taken under uncontrolled illumination.
(ii) Images were taken from different parking lots presenting distinct features.
(iii) Cameras were positioned at different heights. (iv) Images show a varied kind of problems, such as the presence
of shadows, over-exposition to sunlight, low light in rainy days, difference in perspective, and so on.

(v) vehicle images are typical for a commercial surveillance system, i.e., the camera is placed highly above the vehicles, making the detection even more demanding.
(vi) a large number of potential uses.
Although the first and the most important potential use of this dataset is to test the robustness of algorithms with the objective of detecting vacant parking spaces in a real-world surveillance scenario, its application is not restricted to it. Our cameras were placed at different heights and the images were gathered at different climatic conditions. This issue is the strongest point of this dataset. It remains to be seen how will algorithms perform in such variable conditions and how does the vehicle distance from camera influence the results. There is also a potential to test various image preprocessing algorithms, as some of parking spaces are far from the camera mounting position and the perspective plays an important role in such cases.
In addition, by including different pose images of vehicles and parking spaces, we made it possible to use this dataset in modeling parking spaces and vehicles. Other potential uses of this dataset include but are not restricted to: evaluation of algorithms' robustness to different vehicle poses, evaluation of natural illumination normalization algorithms, evaluation of new features for vehicle (or space) description, and so on.
3. Proposed evaluation protocol
This section describes an evaluation protocol proposed on the basis of the PKLot dataset, which is applied in the experiments presented in Section 5.
3.1. Definition of training/testing sets
The strategy used to select images to compose the training and testing sets follows an important rule in the PKLot dataset. This

Fig. 3. Skew adjustment.

Fig. 4. Segmented image: (a) 28 delimited spaces, (b) occupied sub-image, and (c) empty sub-image.

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

Table 1 Summary of the PKLot characteristics.

Parking lot

Weather condition

UFPR04 (28 parking spaces)
UFPR05 (45 parking spaces)
PUCPR (100 parking spaces)
TOTAL

Sunny Overcast Rainy Subtotal
Sunny Overcast Rainy Subtotal
Sunny Overcast Rainy Subtotal

# Of days
20 15 14
25 19 8
24 11 8

# Of images
2098 1408 285 3791
2500 1426 226 4152
2315 1328 831 4474
12,417

# Of parking spaces
Occupied
32,166 (54.98%) 11,608 (29.47%) 2351 (29.54%) 46,125 (43.58%)
57,584 (57.65%) 33,764 (59.27%) 6078 (68.07%) 97,426 (58.77%)
96,762 (46.42%) 42,363 (31.90%) 55,104 (66.35%) 194,229 (45.78%)
337,780 (48.54%)

Empty
26,334 (45.02%) 27,779 (70.53%) 5607 (70.46%) 59,720 (56.42%)
42,306 (42.35%) 23,202 (40.73%) 2851 (31.93%) 68,359 (41.23%)
111,672 (53.58%) 90,417 (68.10%) 27,951 (33.65%) 230,040 (51.46%)
358,119 (51.46%)

4941
Total 58,400 39,387 7958 105,845 99,890 56,966 8929 165,785 208,433 132,780 83,056 424,269 695,899

rule determines that images of the same day can belong to just one of these sets. This avoids that pictures related to the same car parked in the same space for hours showing just light variations can appear in the training and the testing sets simultaneously. With this in mind, we suggest in this protocol to consider 50% of the images available in the subsets UFPR04, UFPR05 and PUCPR for training and 50% for testing. Table 2 shows the amount of samples available for training and testing, which follows this proportion.

3.2. Performance estimation

The performance of the created classifiers on the testing set can be estimated based on the Overall Error Rate (OER) given by Eq. (1).

OER

¼

TP

þ

FP TN

þ þ

FN FP

þ

FN

ð1Þ

where FP; FN; TP, and TN stand for False Positive, False Negative, True Positive, and True Negative, respectively. These statistics can be defined in the 2 Â 2 confusion matrix depicted in Fig. 5.
Another interesting tool for performance estimation is the Receiver Operating Characteristics (ROC) curve. It is created by plotting the TP rate (sensitivity) against the FP rate (specificity) at various threshold settings. An interesting measure of the accuracy is the area under the ROC curve. A test is 100% accurate if both the sensitivity and specificity are 1.0. It means that there are no false positives and no false negatives.

Fig. 5. 2 Â 2 confusion matrix.
3.3. Research directions
Different research directions can be followed on the basis of the PKLot dataset, as follows:
 Single parking lot training and testing: This experiment is devoted to evaluate the suitability of feature sets to represent the presence or absence of a vehicle in a parking space as well as to compare the performance of classifiers trained on descriptors extracted from images that belong to a single parking lot. It means that each classifier is trained on images from one of the training subsets (UFPR04, UFPR05 or PUCPR) and assessed using the respective testing set. For instance, considering UFPR04 as training set, the accuracies and confusion matrices related to the each classifier are computed only for the UFPR04 testing set.

Table 2 Training and testing sets.

UFPR04 UFPR05 PUCPR Total of samples

Sunny Overcast Rainy Total
Sunny Overcast Rainy Total
Sunny Overcast Rainy Total

Training sets
Occupied
16,524 6989 1041
24,554
28,822 15,421
2751 46,994
47,490 26,774 19,540 93,804
165,352

Empty
14,327 15,076
2553 31,956
21,657 12,985
1633 36,275
59,731 42,933 16,025 118,689
186,920

Total
30,851 22,065
3594 56,510
50,479 28,406
4384 83,269
107,221 69,707 35,565
212,493
352,272

Testing sets
Occupied
15,642 4619 1310
21,571
28,762 18,343
3327 50,432
49,271 15,589 35,565 100,425
172,428

Empty
12,007 12,703
3054 27,764
20,649 10,217
1218 32,084
51,941 47,484 11,926 111,351
171,199

Total
27,649 17,322
4364 49,335
49,411 28,560
4545 82,516
101,212 63,073 47,491
211,776
343,627

4942

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

 Single parking lot training and multiple parking lot testing: This experiment allows to measure the generalization power of features and classifiers. For such an aim, classifiers trained on images of a specific parking lot are used to classify images from other parking lots. It means that each classifier is trained on images from one of the training subsets (UFPR04, UFPR05 or PUCPR), however they are assessed using a different testing set. Thus, considering UFPR04 as training set, the accuracies and confusion matrices related to the each classifier are computed for the testing sets available in UFPR05 and PUCPR.
 Multiple parking lot training: here, the classifiers are trained on images of multiple parking lots. Thus, the objective is to measure the ability of the trained classifiers in absorbing the wide variability related to the images captured using different angles of view and camera height mounting as well as presenting varied surface patterns. It means that each classifier is trained on images from two or more of the training subsets (UFPR04, UFPR05 and PUCPR), however they are assessed using a single testing set. Thus, considering the fusion of UFPR04 and UFPR05 as training set, the accuracies and confusion matrices related are computed for the testing set available in PUCPR. In order to produce a balanced training set, we recommend to selected randomly from the UFPR05 and PUCPR training subsets the same amount of images available on UFPR04, which presents the smallest number of training samples.
The list of proposed research directions is not exhaustive. For instance, another direction using the PKLot could be to investigate throughout an error analysis the real impact on the system performance caused by images from different climatic conditions (sunny, rainy and overcast). With such analysis, it is possible to define new features and parameters to make a system fine tuning.
4. Features
As stated before, in this paper we have used two recently developed texture descriptors that have been successfully applied into different application domains. To make this paper self-contained, in this section we briefly describe both descriptors assessed in our experiments, the Local Binary Patterns and Local Phase Quantization.

Fig. 6. LBP uniform pattern (Ojala et al., 2002). (a) the two transitions showed identifies the pattern as uniform. (b) with four transitions, it is not considered a uniform pattern.

That is, the code 00100100 is not considered uniform, because it

contains four transitions, while the code 00100000 is characterized

as uniform, because it only has two transitions. Fig. 6 illustrates

this idea.

Accumulating the patterns that have more than two transitions

into a single bin yields an LBP operator, denoted LBPPu2;R, with fewer
than 2P bins. For example, the number of labels for a neighborhood of 8 pixels is 256 for the standard LBP but 59 for LBPu2. Then, a his-

togram of the frequency of the different labels produced by the LBP

operator can be built (Ojala et al., 1996). LBP variants were proposed in Ojala et al. (2002). LBPri and
LBPriu2 have the same LBPP;R definition, but they have only 36 and 10 patterns, respectively. LBPri accumulates, in only one bin

(Eq. (2)), all binary patterns which keep the same minimum value

LBPrPi;R when their P bits are rotated (ROR). LBPriu2 combines LBPu2 and LBPri definition. Thus, it uses only the uniform binary patterns

and accumulates, in only one bin, those that keep the same mini-

mum decimal value LBPPri;R when their P bits are rotated.

LBPPri;R ¼ minfRORðLBPP;R; iÞ i ¼ 0; . . . ; P À 1g:

ð2Þ

Therefore we have a 59-dimensional feature vector for the standard LBP, a 36-dimensional feature vector for LBPri and a 10-dimensional feature vector for the LBPriu2.

4.1. Local Binary Patterns

4.2. Local Phase Quantization

Ojala et al. (2002) present a model to describe texture, called Local Binary Patterns (LBP). In this model, each pixel C contains a set of neighbors P, equally spaced at a distance R from C. A histogram h is defined by the texture intensity differences between C and its neighbors, P. When the neighbors do not correspond to an image pixel integer value, that value is obtained by interpolation. An important characteristic of this descriptor is its invariance to changes in the value of the average intensity of the central pixels, when comparing it with its neighbors.
Considering the resulting sign of the difference between C and each neighbor P, by definition, we assign a result of 1 to a positive sign, and 0 otherwise. This makes it possible to obtain the invariance of the intensity value of pixels in gray scale format. With this information, the LBP value can be obtained by multiplying the binary elements for a binomial coefficient. So, a value 0 6 C0 6 2P is generated, which is the value of the feature vector.
Observing the non uniformity of the vector obtained, Ojala et al. (2002) introduced a concept based on the transition between 0s and 1s in the LBP image. They explained that a binary LBP code is considered uniform if the number of transitions is less than or equal to 2, also considering that the code is seen as a circular list.

The Local Phase Quantization (LPQ) (Ojansivu & Heikkilä, 2008) is based on the blur invariance property of the Fourier phase spectrum. The local phase information of an N Â N image f ðxÞ is extracted by the 2D DFT (short-term Fourier transform (STFT))

^f ui ðxÞ ¼ ð f Â Uui Þx

ð3Þ

The filter Uui is a complex valued m Â m mask, defined in the discrete domain by

Uui ¼ feÀj2puiT yjy 2 Z2; jjyjj1 6 rg;

ð4Þ

where r ¼ ðm À 1Þ=2, and ui is a 2D frequency vector. In LPQ only four complex coefficients are considered, corresponding to 2D frequencies u1 ¼ ½a; 0T ; u2 ¼ ½0; aT ; u3 ¼ ½a; aT , and u4 ¼ ½a; ÀaT , where a ¼ 1=m. For the sake of convenience, the STFT presented in Eq. (3) is expressed using the vector notation presented in Eq. (5)

^f ui ðxÞ ¼ wuTi fðxÞ

ð5Þ

where wu is the basis vector of the STFT at frequency u and fðxÞ is a vector of length m2 containing the image pixel values from the m Â m neighborhood of x.

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

4943

Let

F ¼ ½fðx1Þ; fðx2Þ; . . . ; fðxN2 Þ

ð6Þ

denote an m2 Â N2 matrix that comprises the neighborhoods for all the pixels in the image and let

w ¼ ½wR; wIÞT

ð7Þ

Table 3 Experimental results by training on UFPR04. Accuracy and confusion matrices of the best single classifier and best fusion scheme for the testing sets (a) UFPR04, (b) UFPR05 and (c) PUCPR.

(a) Testing on UFPR04 LPQu
Occupied Empty Accuracy

Occupied 21,491 140 99.55%

Empty 80 27,624

Mean rule Occupied
Occupied 21,477 Empty 84 Accuracy 99.64%

Empty 94 27,680

(b)Testing on UFPR05 LPQg
Occupied Empty Accuracy

Occupied 41,919 3,928 84.92%

Empty 8,513 28,156

Max Rule
Occupied Empty Accuracy

Occupied 43,077 2,273 88.33%

Empty 7,355 29,811

(c) Testing on PUCPR LPQg
Occupied Empty Accuracy

Occupied 72,898 5,819 84.25%

Empty 27,527 105,532

Max Rule
Occupied Empty Accuracy

Occupied 81,067 5,204 88.40%

Empty 19,358 106,147

where wR ¼ Re½wu1 ; wu2 ; wu3 ; wu4  and wI ¼ Im½wu1 ; wu2 ; wu3 ; wu4 . In this case, RefÁg and ImfÁg return the real and imaginary parts of a complex number, respectively.
The corresponding 8 Â N2 transformation matrix is given by

F^ ¼ wF

ð8Þ

In Ojansivu and Heikkilä (2008), the authors assume that the image function f ðxÞ is a result of a first order Markov process, where the correlation coefficient between two pixels xi and xj is exponentially related to their L2 distance. Without a loss of generality, they define each pixel to have unit variance. For the vector f, this leads to a m2 Â m2 covariance matrix C with elements given by

rci;j ¼ jjxiÀxjjj

ð9Þ

where jj Á jj stands for the L2 norm. The covariance matrix of the Fourier coefficients can be obtained from

D ¼ wCwT

ð10Þ

Since D is not a diagonal matrix, i.e., the coefficients are correlated, they can be decorrelated by using the whitening transformation E ¼ VT F^ where V is an orthogonal matrix derived from the singular value decomposition (SVD) of the matrix D that is

D0 ¼ V T DV

ð11Þ

The whitened coefficients are then quantized using

1 qi;j ¼ 0

if ei;j P 0 otherwise

ð12Þ

Fig. 7. ROC curve of the best classifier of each textural descriptor (LBP and LPQ), and the best fusion scheme using UFPR04 as training set and the testing sets: (a) UFPR04; (b) UFPR05; and (c) PUCPR.

4944

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

where ei;j are the components of E. The quantized coefficients are represented as integer values from 0 to 255 using binary coding

X7 bj ¼ qi;j2i
i¼0

ð13Þ

Finally, a histogram of these integer values from all the image positions is composed and used as a 256-dimensional feature vector in classification.

5. Experiments and results
This section presents the experimental results related to the evaluation protocol proposed in Section 3. As mentioned before, the idea is to introduce the PKLot dataset, providing a baseline performance for researchers and practitioners who plan to use it. The classifier used for the experiments was the Support Vector Machine (SVM) introduced by Vapnik (1998). Normalisation was performed by linearly scaling each attribute to the range [À1, +1]. The free parameters of the system and for SVM training were chosen using 5-fold cross validation. Different kernels were evaluated, and the best results were achieved using a Gaussian kernel.
Parameters C and c were determined through a grid search.
One of the limitations of SVMs is that they do not work in a probabilistic framework. However, there are several situations where it would be very useful to have a classifier which produces a posterior probability PðclassjinputÞ. In our case, we are interested in estimating probabilities because we want to evaluate different fusion strategies, like Sum, Max, Min, Mean, and Median. Due to the benefits of having classifiers estimating probabilities, many researchers have been working on the problem of estimating probabilities with SVM classifiers (Platt, 1999; Sollich, 2002). In this work, we have adopted the strategy proposed by Platt (1999).
5.1. Training on a single parking lot
The experiments here are related to the two first research directions suggested in the evaluation protocol presented in Section 3.

They are devoted to compare the performance of classifiers trained on images that belong to a single parking lot. It means that each classifier is trained on images from one of the training subsets (UFPR04, UFPR05 or PUCPR) and assessed using each of the three available testing sets.
As described before, for the textural descriptors we have used the standard LBP and LPQ. For the LBPu2 we have evaluated eight neighbors and different distances, but distance one presented the best results. LPQ was also evaluated for different window sizes and the best results were achieved using a 3 Â 3-sized window. The success of LBP and LPQ in several different applications instigate other researchers to further improve those descriptors. As a result of these efforts, the literature shows that some variations of LBP and LPQ achieve yet better results than the standard descriptors. With this in mind, we have assessed the LBP Rotation Invariant (LBPri) (Ojala et al., 2002), LPQ STFT with

Table 5 Experimental results by training on UFPR05. Accuracy and confusion matrices of the best single classifier and best fusion scheme for the testing sets (a) UFPR04, (b) UFPR05 and (c) PUCPR.

(a) Testing on UFPR04

LPQgd

Occupied

Occupied 19,251

Empty

4,703

Accuracy

85.76%

(b)Testing on UFPR05

LPQu

Occupied

Occupied 49,847

Empty

320

Accuracy

98.90%

(c) Testing on PUCPR LPQu

Occupied

Occupied 92,365

Empty

17,912

Accuracy

87.74%

Empty 2,320 23,061
Empty 585 31,764
Empty 8,060 93,439

Mean Rule
Occupied Empty Accuracy

Occupied 20,685 6,255 85.53%

Mean Rule
Occupied Empty Accuracy

Occupied 50,041 188 99.30%

Mean Rule
Occupied Empty Accuracy

Occupied 97,011 18,133 89.83%

Empty 886 21,509
Empty 391 31,896
Empty 3,414 93,218

Table 4 Summary of the classification results on the testing sets considering UFPR04 for training.

LPQg LPQgd LPQu LBPu LBPri LBPriu2
Mean Rule
Max Rule

UFPR04
AUC
0.9997 0.9999 0.9998 0.9990 0.9685 0.9380 0.9997 0.9994

FPR
0.0062 0.0040 0.0037 0.0164 0.1242 0.1834 0.0044 0.0050

FNR
0.0060 0.0048 0.0050 0.0086 0.0707 0.0915 0.0030 0.0040

UFPR05
AUC
0.9461 0.9368 0.9393 0.9329 0.9393 0.8954 0.9582 0.9595

Bold values are the best values for the measures.

FPR
0.1688 0.2094 0.2090 0.1701 0.2662 0.2972 0.1765 0.1458

FNR
0.1224 0.1031 0.1004 0.1368 0.0549 0.0721 0.0625 0.0708

PUCPR
AUC
0.9423 0.9498 0.9519 0.9149 0.8953 0.8324 0.9713 0.9522

FPR
0.2741 0.5468 0.5198 0.1345 0.3630 0.3315 0.2630 0.1928

FNR
0.0523 0.0050 0.0077 0.2015 0.1144 0.1097 0.0052 0.0467

Fig. 8. Misclassified samples observed in experiment UFPR04/UFPR04.

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

4945

Fig. 9. ROC curve of the best classifier of each textural descriptor (LBP and LPQ), and the best fusion scheme using UFPR05 as training set and the testing sets: (a) UFPR04; (b) UFPR05; and (c) PUCPR.

Table 6 Summary of the classification results on the testing sets considering UFPR05 for training.

LPQg LPQgd LPQu LBPu LBPri LBPriu2
Mean rule
Max rule

UFPR04
AUC
0.9091 0.9313 0.9307 0.8689 0.8835 0.8047 0.9533 0.9298

FPR
0.0848 0.1076 0.1128 0.1763 0.0617 0.0638 0.0411 0.0449

FNR
0.2475 0.1694 0.1669 0.2458 0.4052 0.4600 0.2253 0.2920

UFPR05
AUC
0.9992 0.9994 0.9994 0.9991 0.9801 0.9546 0.9995 0.9991

Bold values are the best values for the measures.

FPR
0.0140 0.0120 0.0116 0.0164 0.0707 0.1004 0.0078 0.0083

FNR
0.0115 0.0106 0.0100 0.0090 0.0705 0.0944 0.0059 0.0061

PUCPR
AUC
0.9310 0.9384 0.9436 0.9343 0.9082 0.8842 0.9761 0.9520

FPR
0.0637 0.1032 0.0803 0.0441 0.0920 0.1089 0.0340 0.0339

FNR
0.2416 0.1495 0.1609 0.3212 0.2366 0.2190 0.1628 0.1826

Fig. 10. Misclassified samples observed in experiment UFPR05/UFPR05.

Gaussian Windows and LPQ Gaussian derivative quadrature filter pair (Rahtu et al., 2012).
Considering UFPR04 as training set, we can see in Table 3 (a, b and c), the accuracies and confusion matrices related to the best

classifier and best fusion schemes observed for the testing sets
available in UFPR04, UFPR05 and PUCPR subsets, respectively. As can be seen, LPQu and the mean rule have shown the best results for the UFPR04 testing set, while LPQ g and the max rule provided

4946

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

Table 7 Experimental results by training on PUCPR. Accuracy and confusion matrices of the best single classifier and best fusion scheme for the testing sets (a) UFPR04, (b) UFPR05 and (c) PUCPR.

(a) Testing on UFPR04

LPQg

Occupied

Occupied 20,310

Empty

5,077

Accuracy 87.15%

(b)Testing on UFPR05 LBPri

Occupied

Occupied 42,088

Empty

5,862

Accuracy 82.78%

(c) Testing on PUCPR

LPQu

Occupied

Occupied 99,911

Empty

374

Accuracy 99.58%

Empty 1,261 22,687
Empty 8,344 26,222
Empty 514 110,977

Mean Rule
Occupied Empty Accuracy

Occupied 20,650 4,563 88.88%

Mean Rule
Occupied Empty Accuracy

Occupied 42,496 5,102 84.20%

Mean Rule
Occupied Empty Accuracy

Occupied 99,944 351 99.61%

Empty 921 23,201
Empty 7,936 26,982
Empty 481 111,000

the best results for UFPR05 and PUCPR testing sets. It is also possible to observe the impact of testing on images from different datasets. The accuracy of the single classifier dropped from 99.55% to 84.25% in the worst case, while a minor loss was observed for the ensemble-based solutions, from 99.64% to 88.33% in the worst scenario. It is worth noting that the improvement on accuracy provided by the fusion schemes, confirms the existence of certain

complementarity among the textural-classifiers in the constructed ensembles.
Fig. 7 shows the ROC curves related to the best LBP and LPQ classifiers, and also to the best combination scheme, for each testing set. All best AUCs are related to variants of the LPQ. We can also see the impact on the AUC when the testing images come from a different parking lot than that used for training the classifiers. Table 4 summarizes the results for each testing set when UFPR04 was used for training, while Fig. 8 presents some samples of misclassified parking spaces.
Similar experiments were done considering UFPR05 as training set. We can see in Table 5 (a, b and c), the accuracies and confusion matrices related to the best classifier and best fusion schemes observed for all the testing sets. As one may see the best results among the single classifiers were provided by those trained on LPQu and LPQ gd features, while the Mean rule was always the best fusion scheme. Similar behavior was observed when a different testing set is used, i.e., a loss in terms of accuracy.
In addition the ROC curves of the best LBP, LPQ and fusion scheme, are shown in Fig. 9 for each testing set. Table 6 summarizes the results for each testing set when UFPR05 was used for training, while Fig. 10 presents some samples of misclassified parking spaces.
Finally, we have evaluated PUCPR as training set. We can see in Table 7 (a, b and c), the accuracies and confusion matrices related to the best classifier and best fusion scheme observed for each testing set. Here LPQu, LPQri and LPQ g were the best single classifiers, while Mean rule was always the best fusion scheme. In addition, the loss in terms of accuracy related to the use of a different testing

Fig. 11. ROC curve of the best classifier of each textural descriptor (LBP and LPQ), and the best fusion scheme using PUCPR as training set and the testing sets: (a) UFPR04; (b) UFPR05; and (c) PUCPR.

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

Table 8 Summary of the classification results on the testing sets considering PUCPR for training.

LPQg LPQgd LPQu
LBPu LBPri LBPriu2
Mean rule
Max rule

UFPR04
AUC
0.9483 0.9479 0.7777
0.9225 0.9006 0.8577
0.9589
0.8826

FPR
0.0585 0.0502 0.9090
0.1131 0.0563 0.0804
0.0427
0.0537

FNR
0.1829 0.2545 0.0006
0.2055 0.3879 0.3410
0.1643
0.2065

UFPR05
AUC
0.8916 0.8792 0.7675
0.8697 0.9152 0.891
0.9194
0.8363

Bold values are the best values for the measures.

FPR
0.1335 0.1313 0.9243
0.1611 0.1655 0.2009
0.1574
0.2186

FNR
0.2904 0.3072 0.0006
0.2890 0.1827 0.1435
0.1590
0.1114

PUCPR
AUC
0.9998 0.9998 0.9999
0.9994 0.9912 0.9794
0.9998
0.9997

FPR
0.0068 0.0052 0.0051
0.0127 0.0559 0.0726
0.0048
0.0053

4947
FNR 0.0043 0.0034 0.0034 0.0063 0.0377 0.0415 0.0032 0.0037

Fig. 12. Misclassified samples observed in experiment PUCPR/PUCPR.

Table 9 Experimental results considering a training process based on multiple parking lots. The classifiers trained on multiple parking lots (ALL) are compared to that trained on UFPR04 subset.

LPQg LPQgd LPQu
LBPu LBPri LBPriu2
Mean rule
Max rule

UFPR04/UFPR04

AUC

FPR

0.9997 0.9999 0.9998

0.0062 0.0040 0.0037

0.9990 0.9685 0.9380

0.0164 0.1242 0.1834

0.9997 0.0044

0.9994 0.0050

FNR
0.0060 0.0048 0.0050
0.0086 0.0707 0.0915
0.0030
0.0040

ALL/UFPR04

AUC

FPR

0.9995 0.9997 0.9997

0.0088 0.0045 0.0051

0.9986 0.9596 0.9525

0.0167 0.0945 0.1094

0.9996 0.0046

0.9993 0.0039

FNR
0.0087 0.0069 0.0075
0.0138 0.1175 0.1761
0.0057
0.0062

Bold values are the best values for the measures.

set is more significant, about 17 and 15 percentage points for the single and the ensemble-based classifiers, respectively. The reason is that the PUCPR subset differs significantly from the other two subsets in terms of ground patterns, angle of view and camera mounting height. The ROC curves of the best LBP and LPQ classifiers, and the best fusion scheme are plotted in Fig. 11, considering each testing set. Table 8 summarizes the results for each testing set

Table 10 Experimental results considering a training process based on multiple parking lots. The classifiers trained on multiple parking lots (ALL) are compared to that trained on UFPR05 subset.

LPQg LPQgd LPQu
LBPu LBPri LBPriu2
Mean rule
Max rule

UFPR05/UFPR05

AUC

FPR

0.9992 0.9994 0.9994

0.0140 0.0120 0.0116

0.9991 0.9801 0.9546

0.0164 0.0707 0.1004

0.9995 0.0078

0.9991 0.0083

FNR
0.0115 0.0106 0.0100
0.0090 0.0705 0.0944
0.0059
0.0061

ALL/UFPR05

AUC

FPR

0.9982 0.9984 0.9986

0.0152 0.0132 0.0138

0.9979 0.9745 0.9467

0.0200 0.1030 0.1485

0.9988 0.0116

0.9980 0.0102

FNR
0.0209 0.0208 0.0189
0.0194 0.0618 0.0780
0.0118
0.0125

Bold values are the best values for the measures.

when PUCPR was used for training, while Fig. 12 presents some samples of misclassified parking spaces.
Through this first set of experiments, we have demonstrated that texture descriptors are a good alternative for parking space detection. Both LBP and LPQ are able to achieve very low error rates with the classifier trained with LPQ and its variants being slightly superior. Our experimental results also show that the combination of all classifiers brings some gain of performance.
With respect to the experiments on testing images captured from a parking lot that has not contributed with images for the training process of the created classifiers, we have observed a significant loss in terms of accuracy and AUC. The classifiers still providing satisfactory performances, but not superior than 90%. An error analysis have shown misclassification related to spaces partially occluded by the car parked on adjacent spaces, occluded by trees, or with significant changes in the surface motivated by shadow or rain.

5.2. Training on multiple parking lots
Here we have considered as suggested in the third research direction pointed out in Section 3, training the classifiers using images from multiples parking lots. For this purpose, the classifiers are created using all training samples available in UFPR04, UFPR05

Table 11 Experimental results considering a training process based on multiple parking lots. The classifiers trained on multiple parking lots (ALL) are compared to that trained on PUCPR subset.

LPQg LPQgd LPQu
LBPu LBPri LBPriu2
Mean rule Max rule

PUCPR/PUCPR

AUC

FPR

0.9998 0.9998 0.9999

0.0068 0.0052 0.0051

0.9994 0.9912 0.9794

0.0127 0.0559 0.0726

0.9998 0.9997

0.0048 0.0053

FNR
0.0043 0.0034 0.0034
0.0063 0.0377 0.0415
0.0032 0.0037

ALL/PUCPR

AUC

FPR

0.9994 0.9997 0.9996

0.0080 0.0058 0.0072

0.9989 0.9755 0.9643

0.0107 0.0827 0.0942

0.9997 0.9993

0.0048 0.0046

FNR
0.0097 0.0063 0.0073
0.0159 0.0577 0.0552
0.0048 0.0060

Bold values are the best values for the measures.

4948

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

Fig. 13. ROC curves of the classifiers trained on multiple parking lots considering as testing sets: (a) UFPR04; (b) UFPR05; and (c) PUCPR.

Table 12 Comparison to related works reported in the literature.

Reference

Features

Wu et al. (2007) Sastre et al. (2007)
Bong et al. (2008) Huang et al. (2008) Ichihashi et al. (2009) Huang and Wang
(2010) Proposed method

Color Gabor filters Color Color PCA Color
Texture

Number of parking spaces
1100 12,150
80 2600 54,000 6912
(UFPR04) 49,335 (UFPR05) 82,516 (PUCPR) 211,776

Error rate (%)
6.5 2.2
7.0 2.5 2.0 1.2
0.4 0.7 0.4

and PUCPR subsets. In order to produce a balanced training set, we have randomly selected from UFPR05 and PUCPR the same amount of images available on UFPR04, which presents the smallest number of training samples.
Tables 9­11 present the results of the classifiers trained on multiple subsets compared with those trained on the subsets UFPR04, UFPR05 and PUCPR, respectively. The ROC curves of these classifiers are shown in Fig. 13. The experiments have shown that in general the trained classifiers may provide similar results than those trained on a specific parking lot.

6. Conclusion
In this paper we introduced a new parking lot dataset composed of 695,899 images captured from two parking lots with three

different camera views. The available images show a wide luminance variation since they were captured under different climatic conditions (sunny, rainy and overcast periods) without any control on the illumination. With the obtained images one is able to evaluate different classification techniques considering the main challenges usually present in a real scenario, such as the presence of shadows, over-exposition to sunlight, low light in rainy days, difference in perspective, and so on. In addition, with a set of comprehensive experiments, we demonstrated that texture-based descriptors are a good alternative to distinguish between empty and occupied parking spaces.
The main contribution of this work is to make available a robust dataset for the scientific community. The PKLot is an important alternative to researchers and practitioners dedicated to create outdoor parking lot vacancy detection systems. It overcomes the problem regarding the lack of a common dataset, allowing future benchmarking and evaluation.
Beyond gaining better insight into the dataset, the experiments on textural descriptors allowed some important observations. The experimental protocol created on the basis of the PKLot dataset, allow us to assess textural-based classifiers on images captured from different parking lots and under significant changes in lightning conditions. Different from the related works in the literature, here only textural-based descriptors were used for classification of parking spaces. The results confirm that such a kind of information is an interesting alternative to distinguish between vacant and occupied parking spaces, well absorbing the large variance on the illumination observed in the images of the PKLot dataset. In the experiments where the same view was used for training and testing, we have reached outstanding recognition rates, greater than

P.R.L. de Almeida et al. / Expert Systems with Applications 42 (2015) 4937­4949

4949

99%. This result compares favorably to the related works in the literature, as shown in Table 12. Finally, different from the usual experimental protocols found in the literature, we have tried to build a general classifier that is able to classify correctly images from the parking lots that were not used for training. The best result achieved by the texture-based classifier was about 89%. This drop in terms of classification performance was expected, however, it shows that additional investigation is necessary. We believe the proposed dataset could be very useful to help design a robust classifier less dependent on the training set.
As future work, with the proposed dataset is possible to evaluate different techniques to create pools of classifiers by varying the parameters of base classifiers, or by playing with the datasets used for training. In such direction, we can also evaluate the use of static and dynamic selection of classifiers from the initial pools. Another direction using the PKLot could be to investigate throughout an error analysis the real impact on the system performance caused by images from different climatic conditions (sunny, rainy and overcast). With such analysis, it is possible to define new features and parameters to make a system fine tuning.
Acknowledgments
This research has been supported by The National Council for Scientific and Technological Development (CNPq) and Araucaria Foundation.
References
Almeida, P., Oliveira, L. S., Silva, E., Britto Jr, A. S., & Koerich, A. (2013). Parking space detection using textural descriptors. In IEEE international conference on systems, man, and cybernetics (SMC), 2013 (pp. 3603­3608). doi: 10.1109/SMC.2013.614.
Bin, Z., Dalin, J., Fang, W., & Tingting, W. (2009). A design of parking space detector based on video image. In ICEMI '09. 9th international conference on electronic measurement instruments, 2009 (pp. 2-253­2-256). doi: 10.1109/ ICEMI.2009.5274579.
Bong, D. B. L., Ting, K. C., & Lai, K. C. (2008). Integrated approach in the design of car park occupancy information system. IAENG International Journal of Computer Science, 35, 1­8.
Chunhe, Y., & Jilin, L. (2004). A type of sensor to detect occupancy of vehicle berth in carpark. In Proceedings. ICSP '04. 2004 7th international conference on signal processing, 2004 (Vol. 3, pp. 2708­2711). doi: 10.1109/ICOSP.2004.1442341.
Costa, Y. M. G., Oliveira, L. S., Koerich, A. L., Gouyon, F., & Martins, J. G. (2012). Music genre classification using lbp textural features. Signal Processing, 92, 2723­2737. http://dx.doi.org/10.1016/j.sigpro.2012.04.023.
Filho, P. L. P., Oliveira, L. S., Nisgoski, S., & Britto, A. S. (Jr.) (2014). Forest species recognition using macroscopic images. Machine Vision and Applications, 25, 1019­1031. http://dx.doi.org/10.1007/s00138-014-0592-7.
Funck, S., Mohler, N., & Oertel, W. (2004). Determining car-park occupancy from single images. In IEEE intelligent vehicles symposium, 2004 (pp. 325­328). doi: 10.1109/IVS.2004.1336403.
Horprasert, T., Harwood, D., & Davis, L.S. (1999). A statistical approach for real-time robust background subtraction and shadow detection. In IEEE international conference on computer vision (pp. 1­19).
Huang, C.-C., Tai, Y.-S., & Wang, S.-J. (2013). Vacant parking space detection based on plane-based bayesian hierarchical framework. IEEE Transactions on Circuits and Systems for Video Technology, 23, 1598­1610. http://dx.doi.org/10.1109/ TCSVT.2013.2254961.
Huang, C.-C., & Wang, S.-J. (2010). A hierarchical bayesian generation framework for vacant parking space detection. IEEE Transactions on Circuits and Systems for Video Technology, 20, 1770­1785. http://dx.doi.org/10.1109/TCSVT.2010.2087510.
Huang, C. -C., Wang, S. -J., Chang, Y. -J., & Chen, T. (2008). A bayesian hierarchical detection framework for parking space detection. In Processing, 2008. ICASSP 2008. IEEE international conference on acoustics, speech and signal (pp. 2097­ 2100). doi: 10.1109/ICASSP.2008.4518055.

Ichihashi, H., Notsu, A., Honda, K., Katada, T., & Fujiyoshi, M. (2009). Vacant parking space detector for outdoor parking lot by using surveillance camera and fcm classifier. In IEEE international conference on fuzzy systems, 2009. FUZZ-IEEE 2009 (pp. 127­134). doi: 10.1109/FUZZY.2009.5277099.
Jermsak, J., Umair, A., Abdulhamid, H., Haiwei, D., & Nikolaos, M. (2014). One-day long statistical analysis of parking demand by using single-camera vacancy detection. Journal of Transportation Systems Engineering and Information Technology, 14, 33.
Lee, C. -H., Wen, M. -G., Han, C. -C., & Kou, D. -C. (2005). An automatic monitoring approach for unsupervised parking lots in outdoors. In 39th annual 2005 international carnahan conference on security technology, 2005. CCST '05 (pp. 271­ 274). doi: 10.1109/CCST.2005.1594862.
Lin, S. -F., Chen, Y. -Y., & Liu, S. -C. (2006). A vision-based parking lot management system. In IEEE international conference on systems, man and cybernetics, 2006. SMC '06 (Vol. 4, pp. 2897­2902). doi: 10.1109/ICSMC.2006.385314.
Mansano, M., Pavesi, L., Oliveira, L., Britto Jr, A. S., & Koerich, A. (2011). Inspection of metallic surfaces using local binary patterns. In IECON 2011 ­ 37th annual conference on IEEE industrial electronics society (pp. 2227­2231). doi: 10.1109/ IECON.2011.6119655.
Ojala, T., Pietikainen, M., & Maenpaa, T. (2002). Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24, 971­987. http:// dx.doi.org/10.1109/TPAMI.2002.1017623.
Ojala, T., Pietikäinen, M., & Harwood, D. (1996). A comparative study of texture measures with classification based on featured distributions. Pattern Recognition, 29, 51­59. doi: <http://dx.doi.org/10.1016/0031-3203(95)000674>.
Ojansivu, V., & Heikkilä, J. (2008). Blur insensitive texture classification using local phase quantization. In A. Elmoataz, O. Lezoray, F. Nouboud, & D. Mammass (Eds.), Image and signal processing. Lecture notes in computer science (Vol. 5099, pp. 236­243). Berlin Heidelberg: Springer. doi: 10.1007/978-3-540-699057_27.
Ojansivu, V., Rahtu, E., & Heikkila, J. (2008). Rotation invariant local phase quantization for blur insensitive texture analysis. In 19th international conference on pattern recognition, 2008. ICPR 2008 (pp. 1­4). doi: 10.1109/ ICPR.2008.4761377.
Platt, J. C. (1999). Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In Advances in large margin classifiers (pp. 61­74). MIT Press.
Rahtu, E., Heikkilä, J., Ojansivu, V., & Ahonen, T. (2012). Local phase quantization for blur-insensitive image analysis. Image and Vision Computing, 30, 501­512. doi: <http://dx.doi.org/10.1016/j.imavis.2012.04.001>. Special Section: Opinion Papers.
Sastre, R., Gil Jimenez, P., Acevedo, F., & Maldonado Bascon, S. (2007). Computer algebra algorithms applied to computer vision in a parking management system. In IEEE international symposium on industrial electronics, 2007. ISIE 2007 (pp. 1675­1680). doi: 10.1109/ISIE.2007.4374856.
Schneiderman, H., & Kanade, T. (2004). Object detection using the statistics of parts. International Journal of Computer Vision, 56, 151­177. http://dx.doi.org/10.1023/ B:VISI.0000011202.85607.00.
Sollich, P. (2002). Bayesian methods for support vector machines: Evidence and predictive class probabilities. Machine Learning, 46, 21­52. http://dx.doi.org/ 10.1023/A:1012489924661.
Tang, V., Zheng, Y., & Cao, J. (2006). An intelligent car park management system based on wireless sensor networks. In 2006 1st international symposium on pervasive computing and applications (pp. 65­70). doi: 10.1109/ SPCA.2006.297498.
Vapnik, V. N. (1998). Statistical learning theory. Wiley-Interscience. Viola, P., & Jones, M. J. (2004). Robust real-time face detection. International Journal
of Computer Vision, 57, 137­154. http://dx.doi.org/10.1023/ B:VISI.0000013087.49260.fb. Wolff, J., Heuer, T., Gao, H., Weinmann, M., Voit, S., & Hartmann, U. (2006). Parking monitor system based on magnetic field sensor. In Intelligent transportation systems conference, 2006. ITSC '06 (pp. 1275­1279). IEEE. doi: 10.1109/ ITSC.2006.1707398. Wu, Q., Huang, C., yu Wang, S., Chiu, W. -C., & Chen, T. (2007). Robust parking space detection considering inter-space correlation. In IEEE international conference on multimedia and expo, 2007 (pp. 659­662). doi: 10.1109/ICME.2007.4284736. Yu, W., & Chen, T. (2009). Parking space detection from video by augmenting training dataset. In ICIP (pp. 849­852). IEEE. Zavaschi, T. H., Britto, A. S., Jr, Oliveira, L. E., & Koerich, A. L. (2013). Fusion of feature sets and classifiers for facial expression recognition. Expert Systems with Applications, 40, 646­655. doi: <http://dx.doi.org/10.1016/j.eswa.2012.07.074>.

