Proceedings of the 16th International IEEE Annual Conference on Intelligent Transportation Systems (ITSC 2013), The Hague, The Netherlands, October 6-9, 2013

MoD6.3

ParkZoom: A Parking Spot Identification System

Abdulla Alasaadi1,+, Juan Aparicio2,+, Nazif Tas2,+, Justinian Rosca2, and Tamer Nadeem1
1Department of Computer Science, Old Dominion University Norfolk, VA 23529, USA
{aalasaad,nadeem}cs.odu.edu 2Siemens Corporation, Corporate Research and Technology
755 College Rd., East Princeton, NJ 08540, USA {juan.aparicio,nazif.tas,justinian.rosca}@siemens.com

Abstract-- Accurate localization in outdoor and indoor spaces is a challenging task. The widely used GPS is not designed for high accuracy applications and yields accuracy levels not sufficient for lane or spot level localization. In addition, errors from inertial sensors accumulate with time due to integration drift. We introduce a smartphone based, infrastructure aided parking localization system called ParkZoom for estimating (zooming into) the precise parking spot location of a vehicle during traversal in both indoor and outdoor parking lots. On the vehicle side, the proposed method utilizes conventional smartphones for generating and transferring continuous sensor data, such as accelerometer, gyroscope, and compass readings. On the infrastructure side, ParkZoom employs statistical learning of sensor data signatures, pattern classification of data, constraint propagation and error correction for accurate parking spot identification. The paper presents experimental results with the ParkZoom algorithm obtained on real data in city driving and two parking areas.
I. INTRODUCTION
Traditional parking solutions are very cumbersome for the user. First, drivers need to search for an available parking spot, a stressful process especially in large and crowded garages like airports and hospitals, where the time is critical. Second, drivers need to remember the zone where they have parked and, in some cases, even the parking spot number. Some parking lots use signs and colors to solve this problem, but even though parking signs are helpful, a related study [1] shows that 62 percent of drivers thought that parking signage are not enough. Third, the user needs to deal with the payment process, which can be also demanding. The driver has to get out of the car, find the parking meter, forecast and input a tentative parking time, get the ticket, and go back to the car to put the ticket in the dashboard. More advanced solutions enable users to speed up the entire parking process with phone payment, e.g. the service offered by companies such as ParkMobile [2] or ParkNow [3]. However, the driver still has to know the parking slot number in which the car is parked as the parking operator or system is unaware of the location of the car until the user inputs that information in the system, either with a call, SMS or web form. A straight forward solution to vehicle's parking
This work is sponsored by Siemens Corporation. +These authors are ordered alphabetically and contributed equally to this work.

spot identification would be the use of phone's GPS readings, widely exploited in other localization services, e.g. OriginDestination Navigation, or geo-tagging of pictures. The problem of parking spot localization is unique in that parking spots are small in size and each parking spot is located next to several other parking spots, making the spot localization and identification process difficult. Infrastructure-intensive parking solutions offer spot by spot parking detection through spot-level sensors, such as Street-line parking sensor networks. However, such systems are difficult to scale and require large investments in infrastructure deployment and support.
We envision a parking system which is capable of detecting the precise parking spot where a vehicle is parked, with minimum infrastructure deployment costs and minimum user interaction. Such a system would exploit the unique characteristics and maneuvers associated with parking, leveraging readings from standard smartphone sensors. Sensors such as accelerometers, gyroscopes, and orientation sensors are able to explore the physical characteristics and movement in the environment, which can be utilized to uniquely characterize a spatial point. Our solution, ParkZoom, is based on the ability of smartphones inside vehicles to gather data from its sensors and communicate this information to the infrastructure backend system, as shown in Figure 1. The backend system filters and constrains the data based on the physical layout of the parking lot to return with increased accuracy the position of the vehicle, eventually detecting the parking spot or the zone where the car is parked.
In this paper, we first provide an overview of related work in this area. Then, in Section 3 we give an outline of our parking localization framework called ParkZoom, describing its assumptions and components. Section 4 gives details about two ParkZoom's components: turn detection and distance calculation. Section 5 presents results and evaluation approach and Section 6 ends with conclusions and future work.
II. RELATED WORK
Finding a vehicle in a big parking lot is a common problem. There are smartphone apps like Find my car [4]

978-1-4799-2914-613/$31.00 ©2013 IEEE

702

Start Read raw sensor

Data Filtering

No
Distance Calculation Update Distance on current aisle

Turn Detection Turn
Detected
Yes

Return current parking spot

Yes
Parking Event
Parking Detected
No Reset Distance
Get current aisle

Fig. 1. ParkZoom carries sensor data from moving vehicle to infrastructure, and relays final parking slot back to vehicle or to a backend parking system for further status update, reservation and payment actions.
and myCar locator [5], which use GPS to locate cars in big parking lots. Although the existing solutions are popular, they come with multiple problems. Firstly, their dependence on GPS makes them unusable in indoor parking lots, as the GPS signal is weak in such conditions [6]. Secondly, even in outdoor scenarios, the GPS might produce errors as much as 10 meters [7]. Our solution differs such that it can operate both indoors and outdoors and utilizes only the common smartphones with no additional instrumentation.
Inertial navigation systems (INS) have been used in locating moving objects like ships, airplanes, submarines, robots, and humans. Such systems use inertial sensors with other inputs to estimate the correct location of a moving object. In [8], a low cost INS is used for estimating the location of a car in places where the GPS reception is weak. However, errors from inertial sensors accumulate over time. This is also true for existing Android apps like greenMeter [9], which calculates the distance traveled using accelerometer data. A technique to overcome this problem is to periodically correct position with external inputs. Other systems [8], [10] take advantage of the GPS to periodically correct sensor readings using a Kalman filter. Speedometer of the vehicle [11], [12] or special sensors placed on the wheels [13] can be also exploited for resetting the INS errors. In addition, INS can be used for detecting turns and other activities [11], [12].
III. SYSTEM OVERVIEW
Even though conventional smartphones are usually equipped with GPS chips, GPS technology is not suitable for our parking spot localization scenario because of the following reasons:
· Spot identification requires high resolution accuracy that GPS does not provide. Current localization systems, such as GPS and Dead Reckoning, are erroneous and have limited position accuracy. For instance, widely used GPS is not designed for high accuracy applications, and yields an accuracy level of 5 meters in open sky setting, 7 meters in young forest conditions and 10 meters under closed canopies [7].

Fig. 2. ParkZoom data processing overview.
· GPS performance degrades in indoor and in urban environments (e.g., Manhattan). Performance of GPS based systems is questionable in indoor areas [8], [12].
In order to overcome GPS problem, our system utilizes the INS approach. ParkZoom recognizes noisy readings obtained from inertial sensors and utilizes the parking lot geometry information to periodically calibrate the sensors.
In a typical parking lot, such as in the example presented in Figure 1, a vehicle's movement could be represented as a series of actions, each action categorized as one of the two main movements: a) turning at turning point ; and b) moving along an aisle which connects two turning points. Thus, parking maps can be represented as graphs where nodes represent turns and links represent aisles. As the information gathered at the infrastructure side evolves over time, so does the navigation of the vehicle along the graph. As a consequence, the localization problem can be divided into two subcomponents we will highlight here: turn detection and distance calculation within an aisle.
The first sub-component, the turn detection and classification module, has the responsibility to process the signals sent by the vehicles and apply learning-based signal processing techniques for recognizing and classifying the different turns along the vehicle's path. The physical movement characteristics through the parking environment can be leveraged to uniquely characterize a spatial point.
The second sub-component, the distance calculation module, is in charge of calculating the distance traveled on the last aisle and specifying the parking specific spot. However, it not only calculates the distance at the last aisle, but also performs the distance calculation at any point in time and stores this value. Aisle length and turning point locations are known by the infrastructure. Before reaching its destination, a car would traverse a random number of aisles and turns until it finds an empty parking spot. Turning points along the route also serve as "learning points or checkpoints" where the real distance traveled can be compared with the calculated value. The difference can then be taken into account in the last aisle distance calculation.
Figure 2 gives an overview of the logic behind our system. We assume the system detects the single entrance of the

978-1-4799-2914-613/$31.00 ©2013 IEEE

703

parking-lot. Then periodically, the smartphone in the vehicle collects sensor data, which is filtered, smoothed and finally sent to the turn detection module. If no turn is detected, the distance calculation module keeps calculating and updating the distance traveled in the current aisle. Alternatively, if a turn is detected, the system checks if this turn is a parking turn or an aisle changing turn. If the latter is true, the system updates the current aisle using the parking lot geometry information, and continues the process with the updated aisle. Finally, once the system detects that the car has initiated the final parking maneuvers, the system estimates the parking spot location based on the current aisle in the parking lot geometry, and the distance traveled on that aisle.
IV. METHODOLOGY
A. TURN DETECTION
In this section, we describe the turn detection algorithm. Parkzoom relies on two stages: (1) identification of the corridor (aisle) the vehicle is in, through turn detection in a constrained parking lot geometry; (2) calculation of the distance traveled to estimate the exact spot the vehicle is on. The turn detection is an essential component of our system, as it enables ParkZoom to navigate through the logical parking lot diagram in order to identify the exact corridor in which the vehicle is cruising. Our proposed methodology does not assume any infrastructure sensor support and depends entirely on the built-in smartphone sensors. Our solution utilizes a mixture of smartphone sensors in order to identify (1) if there is a turn at a given time; (2) the degree and the direction of the turn (i.e. right or left). In the following sections, we will discuss these items in more detail.
1) Turn Identification: Identifying a turn at a given time is not a straightforward task. A naive threshold-based mechanism, such as detection of turns if the accelerometer reading is greater than a threshold (e.g., 1.0m/s2), can fail easily as this threshold heavily depends on the speed in the turn, type of car, and the orientation of the smartphone.We employ a learning-based signal-processing mechanism for recognizing specific irregular signal patterns subject to background noise. This learning-based methodology also enables us to filter out the irregular maneuvers that do not correspond to vehicle turns. For efficiently and autonomously identifying signal patterns, we deploy a more sophisticated learning-based signal-processing mechanism, which we have developed in house for a different purpose: 2-class Audio Verification Framework (AVF) [14]. AVF takes target and background audio signals for the initial training phase. After the training stage is completed, the system can be deployed and run continuously without any human interaction.
AVF is designed for audio signals. However, audio signals are not much different than any other sensor signals, such as the accelerometer signals on a smartphone. In our proposed turning detection algorithm, we have utilized our proven AVF on the accelerometer data. After the initial training stage, our trained model can be directly used to identify the turns in real time. AVF supports multiple learning methods such as vector

Fig. 3. Overview of ParkZoom turn detection mechanism.
quantization (VQ) and Hidden Markov Models (HMM)[15]. The results being presented in this paper pertains to the VQ model, however, we have also observed similar results when other learning methods were utilized. There are two major differences between the audio and accelerometer readings that have to be addressed before we can use AVF on the latter: (1) the sampling rate of the accelerometer readings on a typical smartphone is not uniform, hence the signal has to be interpolated for uniform sampling; (2) as the patterns are not always visually recognizable, a secondary ground truth tagging mechanism is required. In our experiments, we have chosen to manually tag the training data through voice recordings at the data collection stage. Once the accelerometer data is uniformly sampled, AVF can be applied on the identified target data and the background data in order to train the final model.
AVF can identify when a turn is occurring, however, it falls short on detecting the degree of the turn, which is essential for our system in order to discover the exact corridor the vehicle is in. Indeed, we have attempted to utilize the AVF for detecting the degree of the turn as well, through discretizing the different degree turns into different classes (for instance, we specified 90 degree turns and 180 degree turns into different classes). However, we have observed that AVF lacks the accuracy needed to classify different turning angle classes1. However, as will be discussed further, AVF is very accurate in identifying when the turn is occurring without identifying the magnitude of the turn.
2) Identification of the Degree and the Direction of the Turns: In addition to the accelerometer sensors, today's typical smartphone is also equipped with a gyroscope sensor, which measures the rate of rotation around the device's three local axes. Theoretically, numerical integration of these readings is expected to give the angular displacement as gyroscope sensor readings essentially measure the speed of rotation. However, even though the gyroscope integration is accurate in the short term, it tends to drift heavily in the long term, making it ineffective for continuous use. Our system is already capable of identifying the exact times that the turns are occurring, therefore we can limit our usage of gyroscope sensor data only to the time intervals that mark the exact
1We omit these results due to space limitation.

978-1-4799-2914-613/$31.00 ©2013 IEEE

704

start and end times of the turns. Thus, our system relies on the gyroscope data only for the duration of a turn, which is almost never expected to be more than several seconds.
Figure 3 illustrates how our overall turning detection algorithm works.
B. DISTANCE CALCULATION
In order to calculate the distance traveled, we use the linear acceleration readings to get the speed and the distance as follows:

V [i] = V [i - 1] + a[i]  dt

(1)

D[i] = D[i - 1] + V [i - 1]  dt +  a[i]  dt  dt (2)

where a[i] is the linear acceleration at time i, D[i] is distance traveled at time i, and V [i] is velocity at time i.
The distance calculation using equations (1) and (2) accumulates errors over time and needs to be calibrated. The typical scheme to calibrate the calculation is Kalman filter. In [8], [12] authors used inertial sensors in navigation and Kalman filter to correct the inertial sensors readings. Kalman filter uses other sources to calibrate the INS, so systems use either the GPS, car speedometer, or special sensors installed on the wheels to correct the inertial sensor readings whenever available. As previously discussed, GPS is not suitable for our system because we expect the system to work indoors and the accuracy of smartphone's GPS is not enough to locate the car parking spot. Also, we can not use the car speedometer or any external sensors that calculate speed as our system is based on smartphones. Consequently, Kalman filter is not applicable to our approach because our approach needs to accurately locate the parking spot without updating the calculation with readings from external sensors.
Our method uses the fact that the exact location of the turns in the parking lot and the length of every aisle are known. This allows us to correct the accumulated error of the accelerometer. As we know the geometry of the parking lot and we can detect turns accurately, the challenge now is to calculate the distance traveled from the beginning of the aisle to the final parking spot. In addition to the turning points, we could use additional checkpoints in aisles to calibrate or reset distance calculations for more accurate results. These unique signatures or checkpoints can be related to a specific maneuver, e.g. turn [16], or encoded into the pavement via natural irregularities, e.g. bumps or potholes [17], [18], [19], or artificial irregularities, e.g. "Braille-like" pavement stripes [20]. In addition, other readings from alternative phone sensors, such as temperature, pressure, sound or radio signal strength, could also be associated to specific zones in a parking. For simplicity we will consider only turns as checkpoints.
In order to build our distance calculation module, we studied the driving behavior in parking lots, and collected the inertial sensor readings together with the GPS and video recordings for every experiment. After analyzing the data of the aisles, we found that there are three driving modes that

Start

No
Filter and Smooth Distance calculation Classify Driving Modes

Read raw sensors
Turn Detected

Yes

Reset Distance

Calculate Error

Error Correction Update Distance

Fig. 4. ParkZoom distance calculation components.

are repeated in every aisle in which we refer to as multimodal driving. The first mode is at the beginning of the aisle, where driver starts to accelerate, the second mode is in the middle of the aisle where driver drives in almost constant speed which makes the acceleration close to zero, and the last mode is at the end of the aisle where driver decelerates. Typically, drivers go through the three modes because the parking-lot geometry forces drivers to drive in low speed and apply the same acceleration and deceleration behaviors at the same turning points. In addition, we observed that the error in calculating the distance relates to the mode of the acceleration, and the ratio between the error in modes is almost constant. We used this information to calculate error rates e1, e2, and e3 in the first, second, and third modes respectively. Furthermore, we use this observation to build data clusters for the three different modes, which we use to estimate the error while driving as follow:

(D1 + D1  e1) + (D2 + D2  e2) + (D3 + D3  e3) =  (3)

where D1 is distance calculated in first mode using equation (2), D2 and D3 are distances calculated in second and third

modes respectively, and  is the actual traveled distance.

From several experiments, we found the relations between

e1, e2 and e3 could be approximated by the following

equations:

e1/e2 = c1

(4)

e2/e3 = c2

(5)

where c1 and c2 are constants and are estimated from the training data. Hence, after the first isle, we could solve equations (3), (4), and (5) to get e1, e2, and e3 that will be used to calculate the distance in the next aisle. At the end of each aisle, we solve the same equations to get new error values that can be used for the next aisle.
A typical parking scenario will involve several turns before the final parking maneuver. We use the data collected from all aisles before the final parking to calculate the error over each aisle and then we compensate for this error in the next aisle. We refer to this process as forward error correction.
In order to examine how the two components, multi-modal driving and forward error correction, function together, we

978-1-4799-2914-613/$31.00 ©2013 IEEE

705

TABLE I DISTANCE CORRECTION EXAMPLE ON AN AISLE OF 9 SEGMENTS, EACH
SEGMENT IS 6 METERS LONG. VALUES ARE IN METERS.

Round S1 S1 S5 S5 S9 S9

Number

corrected

corrected

corrected

1 2.7 4.6 4.3

2 3.2 7.11 5.3 6.9 4.9 6.8

3 3.4 6.37 5.5 6.2 3.8 4.6

4 3.3 5.82 3

5.7 4.9 7.7

5

3.2 5.81 5.1 5.78 4.5

5.5

6 2.9 5.4 4.9 5.7 4.1 5.4

created a simple experiment. We divided a parking lot aisle into 9 segments of 6 meters. We drove through this aisle six times and applied our forward error correction mechanism after each round. Ground truth values are gathered through visual checkpoints and video recordings. We observed that the first segment, S1, belongs to the first mode; the fifth segment, S5, belongs to the second mode, and the last segment, S9, belongs to the third mode. Table I illustrates the distance calculated with and without forward error correction mechanism. Notice that the distance calculated through the proposed mechanism yields much better results on average (i.e. much closer to 6 meters, for each segment). Moreover, the average distance error values are higher for the segments S1 and S9, in comparison with S5, which supports our motivation for multi-modal driving categorization.
Figure 4 summarizes the distance calculation module. As a first step, this module filters and smoothens the noise from linear acceleration readings. Afterwards, the distance traveled is calculated through equations (1) and (2). The system classifies the driving mode and estimate the error in calculating the distance while driving in aisles. We use the forward error correction to correct the calculated distance.
V. EXPERIMENTS AND RESULTS
A. Turn Detection
We have implemented our system in Matlab and have performed extensive experiments to validate its performance. Figure 5 illustrates the results for turn detection. In this experiment, we executed several 90 and 180 degree turns in succession. In addition, we collected data on a highway, which does not contain turns with large radius, to be used as background data. In Figure 5, the top graph shows the ground truth values for 90 degree and 180 degree turns, while the bottom graph shows the decoded turn detection results through the combination of AVF turn recognition mechanism and numerical integration of gyroscope sensor readings. Note that the decoded results illustrate very accurate turning times and degree values, identifying a clear differentiation between 90 and 180 degree turns.
B. Distance Calculation
In order to measure the performance of the distance calculation module, we conducted a driving experiment which consists of several turns and different final parking locations. This experiment is performed to illustrate that the distance between the beginning of the aisle and the final

Fig. 5. ParkZoom turn detection mechanism yields highly accurate results for detecting the time and degree of turns.
Fig. 6. ParkZoom calculation of the distance from the last turn. x-axis is the distance between the final parking maneuver and the last turn performed.
maneuver taken to park the car is enough to determine the parking spot.
Figure 6 illustrates the error values before and after applying the distance calculation technique mentioned in previous sections. The system applies correction mechanisms while driving, and outputs the distance traveled between any two turns.
The x-axis in the figure denotes the distance between the final parking maneuver and the last turn performed. In the first ten meters, the estimated distance was less than the actual distance by almost 3.3 meters, which goes up to two parking spaces. After correcting the distance, the error became around 1.7 meters. The results in Figure 6 shows that, the corrected distance is more accurate than the estimated. The results also showed that if an error value less than two meters is desired (i.e. one parking space), then the required landmark granularity is around one landmark for every four parking spaces. The landmarks vary in nature and even a small bump on the aisle can be a landmark provided that it can be detected by the inertial sensors.
C. ParkZoom Example This subsection reports on the overall evaluation of the
ParkZoom mechanism through an example. We partitioned a parking lot into turns and aisles, and labeled every parking space. We cruised along the parking lot multiple times, parking at different randomly selected final spot each time.

978-1-4799-2914-613/$31.00 ©2013 IEEE

706

F E7
G E8
H

E6 E4 E9 A

E E5 D E3
E1

C E2
B

Node [Turn] Edge [Aisle] Actual Path Estimated Park In-Aisle Landmark
Fig. 7. Parking lot diagram for the ParkZoom example.
In every experiment, we enter the parking lot from the main entrance (node A) as seen in Figure 7. Different paths and parking spaces were chosen in different experiments. In each experiment, the ParkZoom application utilized the sensor data such that (1) the turn detection module identified the aisle taken, (2) the distance calculation module calculated the distance traveled on the aisle and specified the parking space.
In the example scenario shown in Figure 7, the car entered the parking lot from the main entrance, and followed a path of right, left and left turns, before finally stopping at a parking space on the right. After processing the data, the system was accurate in detecting all turns, and specifying exact aisle of the vehicle's parking spot. In Figures 7 8, the green arrow illustrates that the estimated location is one space to the right of the right location, and the purple arrow shows the estimated location if we place landmarks every four parking spots.

Fig. 8. Another ParkZoom Experiment.
VI. CONCLUSION AND FUTURE WORK
In this paper, we introduce ParkZoom, a system to accurately determine a vehicle's parking spot using built-in smartphone sensors and the parking lot geometry. ParkZoom has two components that we focus on in this work: (1) turn detection mechanism for identifying the time and degree of the turns in order to locate the aisle the vehicle is cruising, and (2) distance calculation to estimate the distance traveled

on the current aisle. Real-world experiments with data
collected from two simple and regular parking geometries
showed good accuracy in detecting turns and parking space
determination.
Future work will extensively test this approach in more
rich indoor and outdoor settings, deal with multiple en-
trances, and assess smartphone-only and hybrid deployment
solutions.
REFERENCES
[1] W. S. Associates, "Parking management systems: Needs assessment report," 1999.
[2] "Parkmobile app." [Online]. Available: http://us.parkmobile.com/ [3] "Parknow app." [Online]. Available: http://www.parknow.us/ [4] eLibera, "Find my car app." [Online]. Available: https://play.google.
com/store/apps/details?id=com.elibera.android.findmycar [5] nomandRobot, "Mycar locator app." [Online]. Available: https://play.
google.com/store/apps/details?id=com.nomadrobot.mycarlocatorfree [6] J. Werb and C. Lanzl, "Designing a positioning system for finding
things and people indoors," Spectrum, IEEE, vol. 35, no. 9, pp. 71­ 78, 1998. [7] M. G. Wing, A. Eklund, and L. D. Kellogg, "Consumer-grade global positioning system (gps) accuracy and reliability," Journal of Forestry, vol. 103, no. 4, pp. 169­173, 2005. [8] P. Davidson, J. Hautama¨ki, J. Collin, and J. Takala, "Improved vehicle positioning in urban environment through integration of gps and lowcost inertial sensors," in Proceedings of the the European Navigation Conference (ENC09), 2009. [9] G. Meter, "Green meter app." [Online]. Available: http://www. greenmeter.com/ [10] C. Thompson, J. White, B. Dougherty, A. Albright, and D. C. Schmidt, "Using smartphones to detect car accidents and provide situational awareness to emergency responders," in Mobile Wireless Middleware, Operating Systems, and Applications. Springer, 2010, pp. 29­42. [11] J. Georgy, A. Noureldin, M. J. Korenberg, and M. M. Bayoumi, "Lowcost three-dimensional navigation solution for riss/gps integration using mixture particle filter," Vehicular Technology, IEEE Transactions on, vol. 59, no. 2, pp. 599­615, 2010. [12] L. I. Iozan, J. Collin, and J. Takala, "Integrating mems sensors with gps technology for obtaining a continuous navigation solution in urban areas," in SPAMEC 2011, 2011. [13] M. Reinstein and M. Hoffmann, "Dead reckoning in a dynamic quadruped robot: Inertial navigation system aided by a legged odometer," in Robotics and Automation (ICRA), 2011 IEEE International Conference on. IEEE, 2011, pp. 617­624. [14] V. Ramasubramanian, S. Thiyagarajan, G. Pradnya1, H. Claussen, and J. Rosca, "Two-class verifier framework for audio indexing," in IEEE International Conference on Acoustics, Speech and Signal Processing, 2013. [15] V. Ramasubramanian, R. Karthik, S. Thiyagarajan, and S. Cherla, "Continuous audio analytics by hmm and viterbi decoding," in Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 2396­2399. [16] S. Boonmee and P. Tangamchit, "Portable reckless driving detection system," in Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, 2009. ECTI-CON 2009. 6th International Conference on, vol. 1. IEEE, 2009, pp. 412­415. [17] P. Aksamit and M. Szmechta, "Distributed, mobile, social system for road surface defects detection," in Computational Intelligence and Intelligent Informatics (ISCIII), 2011 5th International Symposium on. IEEE, 2011, pp. 37­40. [18] J. Eriksson, L. Girod, B. Hull, R. Newton, S. Madden, and H. Balakrishnan, "The pothole patrol: using a mobile sensor network for road surface monitoring," in ACM MobiSys, 2008. [19] A. Mednis, G. Strazdins, R. Zviedris, G. Kanonirs, and L. Selavo, "Real time pothole detection using android smartphones with accelerometers," in Distributed Computing in Sensor Systems and Workshops (DCOSS), 2011 International Conference on. IEEE, 2011, pp. 1­6. [20] H. Claussen, J. Aparicio, J. Rosca, and N. C. Tas, "IPASS: Intelligent pavement signaling System," in Intelligent Transportation Systems (ITSC), 2012 15th International IEEE Conference on. IEEE, 2012, pp. 666­671.

978-1-4799-2914-613/$31.00 ©2013 IEEE

707

